{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gBwiKQGnerN-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from copy import deepcopy\n",
        "import itertools\n",
        "from PriceData import DataProcessing\n",
        "from LSTM import LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MARSvkGrerOD"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FgLSxzsverOE"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "NUM_EPOCHS      = 1000\n",
        "LEARNING_RATE   = 0.0001\n",
        "\n",
        "HIDDEN_SIZE     = 32            # Dimensionality of hidden units\n",
        "NUM_FC_FEATURES = 128           # Number of output features, first FF layer\n",
        "NUM_LSTM_LAYERS = 2             # Number of LSTM Layers\n",
        "\n",
        "SEQ_LENGTH      = 60            # Length of inputs sequences\n",
        "BATCH_SIZE      = 16\n",
        "\n",
        "# Regular parameters\n",
        "input_size  = 1      # Number of input features\n",
        "output_size = 1      # Number of output features\n",
        "\n",
        "criterion = nn.MSELoss()    # Set MSE as loss function\n",
        "\n",
        "nr_folds = 10               # Number of folds in K-fold cross validation\n",
        "kf = KFold(n_splits = nr_folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wGmuK9vgerOF"
      },
      "outputs": [],
      "source": [
        "learning_rates  = [0.01, 0.001, 0.0001, 0.00001]\n",
        "# batch_sizes     = [32, 64, 128, 256, 512]\n",
        "batch_sizes     = [512]\n",
        "hidden_sizes    = [16, 32, 48, 60]\n",
        "fc_features     = [64, 96, 128, 160]\n",
        "num_lstms       = [2,4,6,8]\n",
        "seq_lengths     = [30, 60, 90, 120]\n",
        "\n",
        "HP_combinations = list(itertools.product(seq_lengths, batch_sizes, learning_rates,\n",
        "                                         fc_features, hidden_sizes, num_lstms))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(HP_combinations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic-CixCyerOF"
      },
      "source": [
        "### Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data_process = DataProcessing(seq_length=SEQ_LENGTH, batch_size=BATCH_SIZE)\n",
        "# X_train, y_train, X_test, y_test = data_process.get_process_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoookzoYerOP"
      },
      "source": [
        "### LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1GgiWuK3erOP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rdr/Documents/Trading_bot/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n"
          ]
        }
      ],
      "source": [
        "# Set device to CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLEZuaT0erOR"
      },
      "source": [
        "### Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ksVtGXz8erOR"
      },
      "outputs": [],
      "source": [
        "## Struct to store model info\n",
        "class ModelInfo():\n",
        "    def __init__(self, loss=float(0)):\n",
        "        self.inputs     = []\n",
        "        self.labels     = []\n",
        "        self.outputs    = []\n",
        "        self.loss       = loss\n",
        "        self.params     = None\n",
        "        self.lstm       = None\n",
        "        self.train_loader  = None\n",
        "        self.val_loader    = None\n",
        "        self.input_scaler  = None\n",
        "        self.output_scaler = None\n",
        "\n",
        "# Store best model of every fold\n",
        "results = {i:ModelInfo() for i in range(nr_folds)}\n",
        "for i in range(nr_folds): results[i].loss = np.inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1RLygOC6erOR"
      },
      "outputs": [],
      "source": [
        "class Hyperparams():\n",
        "    def __init__(self, learning_rate, hidden_size, num_fc, num_lstm, avg_val_error=float(0)):\n",
        "        self.learning_rate  = learning_rate\n",
        "        self.hidden_size    = hidden_size\n",
        "        self.num_fc         = num_fc\n",
        "        self.num_lstm       = num_lstm\n",
        "\n",
        "        self.avg_val_error  = avg_val_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4vYirhP8erOS",
        "outputId": "893208e8-b520-4237-ed33-150e69597344"
      },
      "outputs": [],
      "source": [
        "# for fold, (train_indices, val_indices) in enumerate(kf.split(X_train)):\n",
        "#     print(f'----------\\nFOLD {fold}')\n",
        "\n",
        "#     train_loader, val_loader = data_process.create_fold_sets(train_indices, val_indices)\n",
        "\n",
        "#     results[fold].input_scaler  = data_process.input_scaler\n",
        "#     results[fold].output_scaler = data_process.output_scaler\n",
        "\n",
        "#     hp_results = []\n",
        "#     for learning_rate, hidden_size, num_fc, num_lstm in HP_combinations:\n",
        "#         hp_results.append(Hyperparams(learning_rate, hidden_size, num_fc, num_lstm))\n",
        "\n",
        "#         # Create LSTM object and move it to the GPU\n",
        "#         lstm = LSTM(output_size, input_size, hidden_size, num_lstm, num_fc, device).to(device)\n",
        "\n",
        "#         # Initialize optimizer\n",
        "#         optimizer = torch.optim.Adam(lstm.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "#         epochs_wo_improvement = 0\n",
        "#         for epoch in range(NUM_EPOCHS):\n",
        "#             if epochs_wo_improvement > 50:\n",
        "#                 print('early stopping!')\n",
        "#                 break\n",
        "\n",
        "#             for i, data in enumerate(train_loader, 0):\n",
        "#                 inputs, targets = data\n",
        "#                 targets = targets.reshape(targets.shape[0],1)\n",
        "\n",
        "#                 inputs  = inputs.to(device)\n",
        "#                 targets = targets.to(device)\n",
        "\n",
        "#                 # Zero the gradients\n",
        "#                 optimizer.zero_grad()\n",
        "\n",
        "#                 # Forward pass\n",
        "#                 outputs = lstm.forward(inputs)\n",
        "#                 # Compute loss\n",
        "#                 loss = criterion(outputs, targets)\n",
        "#                 # Backward pass\n",
        "#                 loss.backward()\n",
        "#                 # Parameter update\n",
        "#                 optimizer.step()\n",
        "\n",
        "#             val_results = ModelInfo()\n",
        "#             val_results.loss = 0\n",
        "#             val_results.params = deepcopy(lstm.state_dict())\n",
        "#             val_results.model  = deepcopy(lstm)\n",
        "#             with torch.no_grad():\n",
        "#                 for i, val_data in enumerate(val_loader, 0):\n",
        "#                     val_inputs, val_targets = val_data\n",
        "#                     val_targets = val_targets.reshape(val_targets.shape[0], 1)\n",
        "\n",
        "#                     val_inputs  = val_inputs.to(device)\n",
        "#                     val_targets = val_targets.to(device)\n",
        "\n",
        "#                     val_outputs = lstm.forward(val_inputs)\n",
        "#                     val_loss = criterion(val_outputs, val_targets)\n",
        "\n",
        "#                     for i in range(val_inputs.shape[0]):\n",
        "#                         single_input = val_inputs[i].flatten()\n",
        "#                         single_label = val_targets[i]\n",
        "#                         single_output = val_outputs[i]\n",
        "\n",
        "#                         val_results.inputs.append(single_input)\n",
        "#                         val_results.labels.append(single_label)\n",
        "#                         val_results.outputs.append(single_output)\n",
        "\n",
        "#                     val_results.loss += float(val_loss.item())\n",
        "#             val_results.loss /= len(val_loader)\n",
        "\n",
        "#             if results[fold].loss > val_results.loss:\n",
        "#                 val_results.train_loader  = deepcopy(train_loader)\n",
        "#                 val_results.val_loader    = deepcopy(val_loader)\n",
        "#                 val_results.input_scaler  = deepcopy(results[fold].input_scaler)\n",
        "#                 val_results.output_scaler = deepcopy(results[fold].output_scaler)\n",
        "#                 results[fold]             = deepcopy(val_results)\n",
        "\n",
        "#                 print(f'epoch {epoch} | validation loss: {val_results.loss} | new best model!')\n",
        "#                 epochs_wo_improvement = 0\n",
        "#             else:\n",
        "#                 print(f'epoch {epoch} | validation loss: {val_results.loss}')\n",
        "#                 epochs_wo_improvement += 1\n",
        "\n",
        "#         X_test_norm, y_test_norm, _, _ = data_process.normalize(X_test, y_test, results[fold].input_scaler, results[fold].output_scaler, fit=0)\n",
        "\n",
        "#         lstm_test = results[fold].model\n",
        "\n",
        "#         lstm_test.load_state_dict(results[fold].params)\n",
        "\n",
        "#         # Set the model to evaluation mode\n",
        "#         lstm_test.eval()\n",
        "\n",
        "#         X_test_norm = X_test_norm.to(device)\n",
        "#         test_output = lstm_test.forward(X_test_norm).to(device)\n",
        "\n",
        "#         test_output_np = test_output.cpu().data.numpy()\n",
        "#         test_labels_np = y_test_norm.data.numpy()\n",
        "#         test_labels_np = test_labels_np.reshape(test_labels_np.shape[0], 1)\n",
        "\n",
        "#         X_plot = results[fold].input_scaler.inverse_transform(test_output_np)\n",
        "#         y_plot = results[fold].output_scaler.inverse_transform(test_labels_np)\n",
        "\n",
        "#         errors = np.abs(X_plot - y_plot)\n",
        "#         avg_error = np.mean(errors)\n",
        "#         print(f'Average test error: {avg_error}\\n')\n",
        "\n",
        "#         hp_results[-1].avg_val_error\n",
        "\n",
        "#     best_avg_val_loss = np.inf\n",
        "#     best_config       = None\n",
        "#     for hp_result in hp_results:\n",
        "#         if hp_result.avg_val_loss < best_avg_val_loss:\n",
        "#             best_config = hp_result\n",
        "#             best_avg_val_loss = hp_result.avg_val_loss\n",
        "#     print('----------')\n",
        "#     print(f'Best config:')\n",
        "#     print(f'    learning rate       : {hp_result.learning_rate}')\n",
        "#     print(f'    hidden size         : {hp_result.hidden_size}')\n",
        "#     print(f'    num of fc features  : {hp_result.hidden_size}')\n",
        "#     print(f'    num of lstm layers  : {hp_result.hidden_size}')\n",
        "#     print(f'    AVERAGE VAL ERROR   : {hp_result.avg_val_loss}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSTUZPquerOT"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 | validation loss: 0.10369424894452095 | new best model!\n",
            "epoch 1 | validation loss: 0.10136613249778748 | new best model!\n",
            "epoch 2 | validation loss: 0.09909230843186378 | new best model!\n",
            "epoch 3 | validation loss: 0.0968654528260231 | new best model!\n",
            "epoch 4 | validation loss: 0.09468969330191612 | new best model!\n",
            "epoch 5 | validation loss: 0.09258710592985153 | new best model!\n",
            "epoch 6 | validation loss: 0.09054819867014885 | new best model!\n",
            "epoch 7 | validation loss: 0.08856380730867386 | new best model!\n",
            "epoch 8 | validation loss: 0.08664322644472122 | new best model!\n",
            "epoch 9 | validation loss: 0.08478881418704987 | new best model!\n",
            "epoch 10 | validation loss: 0.08299784734845161 | new best model!\n",
            "epoch 11 | validation loss: 0.08124902844429016 | new best model!\n",
            "epoch 12 | validation loss: 0.07955995947122574 | new best model!\n",
            "epoch 13 | validation loss: 0.07792172953486443 | new best model!\n",
            "epoch 14 | validation loss: 0.07633668929338455 | new best model!\n",
            "epoch 15 | validation loss: 0.07479937374591827 | new best model!\n",
            "epoch 16 | validation loss: 0.07329796627163887 | new best model!\n",
            "epoch 17 | validation loss: 0.0718449056148529 | new best model!\n",
            "epoch 18 | validation loss: 0.07042869552969933 | new best model!\n",
            "epoch 19 | validation loss: 0.06906731426715851 | new best model!\n",
            "epoch 20 | validation loss: 0.06774156913161278 | new best model!\n",
            "epoch 21 | validation loss: 0.06645657122135162 | new best model!\n",
            "epoch 22 | validation loss: 0.06522192619740963 | new best model!\n",
            "epoch 23 | validation loss: 0.06401740200817585 | new best model!\n",
            "epoch 24 | validation loss: 0.06287304684519768 | new best model!\n",
            "epoch 25 | validation loss: 0.06178360432386398 | new best model!\n",
            "epoch 26 | validation loss: 0.060753749683499336 | new best model!\n",
            "epoch 27 | validation loss: 0.0597811508923769 | new best model!\n",
            "epoch 28 | validation loss: 0.0588766485452652 | new best model!\n",
            "epoch 29 | validation loss: 0.05803860165178776 | new best model!\n",
            "epoch 30 | validation loss: 0.05724564753472805 | new best model!\n",
            "epoch 31 | validation loss: 0.056497907266020775 | new best model!\n",
            "epoch 32 | validation loss: 0.055790409445762634 | new best model!\n",
            "epoch 33 | validation loss: 0.055118296295404434 | new best model!\n",
            "epoch 34 | validation loss: 0.05447172932326794 | new best model!\n",
            "epoch 35 | validation loss: 0.053852805867791176 | new best model!\n",
            "epoch 36 | validation loss: 0.05326836369931698 | new best model!\n",
            "epoch 37 | validation loss: 0.05272911675274372 | new best model!\n",
            "epoch 38 | validation loss: 0.052255574613809586 | new best model!\n",
            "epoch 39 | validation loss: 0.05182020738720894 | new best model!\n",
            "epoch 40 | validation loss: 0.05141964182257652 | new best model!\n",
            "epoch 41 | validation loss: 0.05105200968682766 | new best model!\n",
            "epoch 42 | validation loss: 0.05070587433874607 | new best model!\n",
            "epoch 43 | validation loss: 0.05038491263985634 | new best model!\n",
            "epoch 44 | validation loss: 0.05008004978299141 | new best model!\n",
            "epoch 45 | validation loss: 0.049792299047112465 | new best model!\n",
            "epoch 46 | validation loss: 0.049516504630446434 | new best model!\n",
            "epoch 47 | validation loss: 0.04925057291984558 | new best model!\n",
            "epoch 48 | validation loss: 0.048995401710271835 | new best model!\n",
            "epoch 49 | validation loss: 0.04874391667544842 | new best model!\n",
            "epoch 50 | validation loss: 0.04849342256784439 | new best model!\n",
            "epoch 51 | validation loss: 0.04824202507734299 | new best model!\n",
            "epoch 52 | validation loss: 0.0479863416403532 | new best model!\n",
            "epoch 53 | validation loss: 0.04772000014781952 | new best model!\n",
            "epoch 54 | validation loss: 0.04744341038167477 | new best model!\n",
            "epoch 55 | validation loss: 0.04714634828269482 | new best model!\n",
            "epoch 56 | validation loss: 0.046832235530018806 | new best model!\n",
            "epoch 57 | validation loss: 0.04650372080504894 | new best model!\n",
            "epoch 58 | validation loss: 0.046152595430612564 | new best model!\n",
            "epoch 59 | validation loss: 0.04576999321579933 | new best model!\n",
            "epoch 60 | validation loss: 0.04535861499607563 | new best model!\n",
            "epoch 61 | validation loss: 0.04491666704416275 | new best model!\n",
            "epoch 62 | validation loss: 0.04444124177098274 | new best model!\n",
            "epoch 63 | validation loss: 0.04393009468913078 | new best model!\n",
            "epoch 64 | validation loss: 0.04336615093052387 | new best model!\n",
            "epoch 65 | validation loss: 0.04275880195200443 | new best model!\n",
            "epoch 66 | validation loss: 0.04209611751139164 | new best model!\n",
            "epoch 67 | validation loss: 0.041374243795871735 | new best model!\n",
            "epoch 68 | validation loss: 0.04058533348143101 | new best model!\n",
            "epoch 69 | validation loss: 0.0397240836173296 | new best model!\n",
            "epoch 70 | validation loss: 0.038774238899350166 | new best model!\n",
            "epoch 71 | validation loss: 0.037728557363152504 | new best model!\n",
            "epoch 72 | validation loss: 0.03658979572355747 | new best model!\n",
            "epoch 73 | validation loss: 0.03532466106116772 | new best model!\n",
            "epoch 74 | validation loss: 0.03387721721082926 | new best model!\n",
            "epoch 75 | validation loss: 0.03226043563336134 | new best model!\n",
            "epoch 76 | validation loss: 0.030492212623357773 | new best model!\n",
            "epoch 77 | validation loss: 0.028581061400473118 | new best model!\n",
            "epoch 78 | validation loss: 0.026544184423983097 | new best model!\n",
            "epoch 79 | validation loss: 0.02440029475837946 | new best model!\n",
            "epoch 80 | validation loss: 0.02215449884533882 | new best model!\n",
            "epoch 81 | validation loss: 0.019828327000141144 | new best model!\n",
            "epoch 82 | validation loss: 0.017494045197963715 | new best model!\n",
            "epoch 83 | validation loss: 0.015329995658248663 | new best model!\n",
            "epoch 84 | validation loss: 0.013337652198970318 | new best model!\n",
            "epoch 85 | validation loss: 0.011533136013895273 | new best model!\n",
            "epoch 86 | validation loss: 0.00995641853660345 | new best model!\n",
            "epoch 87 | validation loss: 0.008623549249023199 | new best model!\n",
            "epoch 88 | validation loss: 0.007528937887400389 | new best model!\n",
            "epoch 89 | validation loss: 0.0066712480038404465 | new best model!\n",
            "epoch 90 | validation loss: 0.006032675039023161 | new best model!\n",
            "epoch 91 | validation loss: 0.005610620370134711 | new best model!\n",
            "epoch 92 | validation loss: 0.005335160531103611 | new best model!\n",
            "epoch 93 | validation loss: 0.005174171878024936 | new best model!\n",
            "epoch 94 | validation loss: 0.005088878562673926 | new best model!\n",
            "epoch 95 | validation loss: 0.005012341775000095 | new best model!\n",
            "epoch 96 | validation loss: 0.0049345591105520725 | new best model!\n",
            "epoch 97 | validation loss: 0.0048745861276984215 | new best model!\n",
            "epoch 98 | validation loss: 0.004791289800778031 | new best model!\n",
            "epoch 99 | validation loss: 0.004707227926701307 | new best model!\n",
            "epoch 100 | validation loss: 0.004601761000230908 | new best model!\n",
            "epoch 101 | validation loss: 0.0045161747839301825 | new best model!\n",
            "epoch 102 | validation loss: 0.004424900049343705 | new best model!\n",
            "epoch 103 | validation loss: 0.004334727069362998 | new best model!\n",
            "epoch 104 | validation loss: 0.004233910469338298 | new best model!\n",
            "epoch 105 | validation loss: 0.00414012186229229 | new best model!\n",
            "epoch 106 | validation loss: 0.004056293983012438 | new best model!\n",
            "epoch 107 | validation loss: 0.0039782647509127855 | new best model!\n",
            "epoch 108 | validation loss: 0.0039058441761881113 | new best model!\n",
            "epoch 109 | validation loss: 0.0038349610986188054 | new best model!\n",
            "epoch 110 | validation loss: 0.0037518227472901344 | new best model!\n",
            "epoch 111 | validation loss: 0.003699419554322958 | new best model!\n",
            "epoch 112 | validation loss: 0.003632769570685923 | new best model!\n",
            "epoch 113 | validation loss: 0.00355809333268553 | new best model!\n",
            "epoch 114 | validation loss: 0.0034982516663149 | new best model!\n",
            "epoch 115 | validation loss: 0.0034403586760163307 | new best model!\n",
            "epoch 116 | validation loss: 0.0033891587518155575 | new best model!\n",
            "epoch 117 | validation loss: 0.0033342387760058045 | new best model!\n",
            "epoch 118 | validation loss: 0.0032725853379815817 | new best model!\n",
            "epoch 119 | validation loss: 0.003220562357455492 | new best model!\n",
            "epoch 120 | validation loss: 0.0031786701874807477 | new best model!\n",
            "epoch 121 | validation loss: 0.0031171259470283985 | new best model!\n",
            "epoch 122 | validation loss: 0.0030812883051112294 | new best model!\n",
            "epoch 123 | validation loss: 0.0030188565142452717 | new best model!\n",
            "epoch 124 | validation loss: 0.002981128985993564 | new best model!\n",
            "epoch 125 | validation loss: 0.0029307795921340585 | new best model!\n",
            "epoch 126 | validation loss: 0.0028893601847812533 | new best model!\n",
            "epoch 127 | validation loss: 0.002853940473869443 | new best model!\n",
            "epoch 128 | validation loss: 0.0027915448881685734 | new best model!\n",
            "epoch 129 | validation loss: 0.0027581650065258145 | new best model!\n",
            "epoch 130 | validation loss: 0.002734737587161362 | new best model!\n",
            "epoch 131 | validation loss: 0.0026929453015327454 | new best model!\n",
            "epoch 132 | validation loss: 0.002646133187226951 | new best model!\n",
            "epoch 133 | validation loss: 0.002610964816994965 | new best model!\n",
            "epoch 134 | validation loss: 0.0025908591924235225 | new best model!\n",
            "epoch 135 | validation loss: 0.0025492871645838022 | new best model!\n",
            "epoch 136 | validation loss: 0.002506024087779224 | new best model!\n",
            "epoch 137 | validation loss: 0.0024877465330064297 | new best model!\n",
            "epoch 138 | validation loss: 0.0024656683672219515 | new best model!\n",
            "epoch 139 | validation loss: 0.0024161760229617357 | new best model!\n",
            "epoch 140 | validation loss: 0.002384902094490826 | new best model!\n",
            "epoch 141 | validation loss: 0.0023637620033696294 | new best model!\n",
            "epoch 142 | validation loss: 0.0023253164254128933 | new best model!\n",
            "epoch 143 | validation loss: 0.0023059730883687735 | new best model!\n",
            "epoch 144 | validation loss: 0.0022665861761197448 | new best model!\n",
            "epoch 145 | validation loss: 0.0022439456079155207 | new best model!\n",
            "epoch 146 | validation loss: 0.00221460685133934 | new best model!\n",
            "epoch 147 | validation loss: 0.00220257299952209 | new best model!\n",
            "epoch 148 | validation loss: 0.002164446050301194 | new best model!\n",
            "epoch 149 | validation loss: 0.0021465204190462828 | new best model!\n",
            "epoch 150 | validation loss: 0.0021202965872362256 | new best model!\n",
            "epoch 151 | validation loss: 0.0020981371635571122 | new best model!\n",
            "epoch 152 | validation loss: 0.0020729134557768703 | new best model!\n",
            "epoch 153 | validation loss: 0.0020401354413479567 | new best model!\n",
            "epoch 154 | validation loss: 0.0020458351355046034\n",
            "epoch 155 | validation loss: 0.0020011598244309425 | new best model!\n",
            "epoch 156 | validation loss: 0.0019726562313735485 | new best model!\n",
            "epoch 157 | validation loss: 0.0019771389197558165\n",
            "epoch 158 | validation loss: 0.0019322313601151109 | new best model!\n",
            "epoch 159 | validation loss: 0.0019081190112046897 | new best model!\n",
            "epoch 160 | validation loss: 0.001901776238810271 | new best model!\n",
            "epoch 161 | validation loss: 0.0018680860521271825 | new best model!\n",
            "epoch 162 | validation loss: 0.0018385935109108686 | new best model!\n",
            "epoch 163 | validation loss: 0.0018399051041342318\n",
            "epoch 164 | validation loss: 0.0018076765700243413 | new best model!\n",
            "epoch 165 | validation loss: 0.0017895117634907365 | new best model!\n",
            "epoch 166 | validation loss: 0.0017723582568578422 | new best model!\n",
            "epoch 167 | validation loss: 0.0017568551120348275 | new best model!\n",
            "epoch 168 | validation loss: 0.0017347555258311331 | new best model!\n",
            "epoch 169 | validation loss: 0.0017342131468467414 | new best model!\n",
            "epoch 170 | validation loss: 0.0017004144610837102 | new best model!\n",
            "epoch 171 | validation loss: 0.0016907243989408016 | new best model!\n",
            "epoch 172 | validation loss: 0.0016682223649695516 | new best model!\n",
            "epoch 173 | validation loss: 0.0016600089729763567 | new best model!\n",
            "epoch 174 | validation loss: 0.0016325106844305992 | new best model!\n",
            "epoch 175 | validation loss: 0.0016307292389683425 | new best model!\n",
            "epoch 176 | validation loss: 0.0016111003933474422 | new best model!\n",
            "epoch 177 | validation loss: 0.0015866411849856377 | new best model!\n",
            "epoch 178 | validation loss: 0.0015799072571098804 | new best model!\n",
            "epoch 179 | validation loss: 0.0015552699915133417 | new best model!\n",
            "epoch 180 | validation loss: 0.001552798377815634 | new best model!\n",
            "epoch 181 | validation loss: 0.001536748488433659 | new best model!\n",
            "epoch 182 | validation loss: 0.0015143800410442054 | new best model!\n",
            "epoch 183 | validation loss: 0.0015013269730843604 | new best model!\n",
            "epoch 184 | validation loss: 0.001496492128353566 | new best model!\n",
            "epoch 185 | validation loss: 0.0014720069011673331 | new best model!\n",
            "epoch 186 | validation loss: 0.0014702503685839474 | new best model!\n",
            "epoch 187 | validation loss: 0.0014496449730359018 | new best model!\n",
            "epoch 188 | validation loss: 0.0014427184942178428 | new best model!\n",
            "epoch 189 | validation loss: 0.0014254978159442544 | new best model!\n",
            "epoch 190 | validation loss: 0.0014164189924485981 | new best model!\n",
            "epoch 191 | validation loss: 0.001406337134540081 | new best model!\n",
            "epoch 192 | validation loss: 0.001387575815897435 | new best model!\n",
            "epoch 193 | validation loss: 0.0013897056924179196\n",
            "epoch 194 | validation loss: 0.0013713800581172109 | new best model!\n",
            "epoch 195 | validation loss: 0.0013595084310509264 | new best model!\n",
            "epoch 196 | validation loss: 0.0013485172530636191 | new best model!\n",
            "epoch 197 | validation loss: 0.001339380571153015 | new best model!\n",
            "epoch 198 | validation loss: 0.0013362504541873932 | new best model!\n",
            "epoch 199 | validation loss: 0.0013171480968594551 | new best model!\n",
            "epoch 200 | validation loss: 0.001323006406892091\n",
            "epoch 201 | validation loss: 0.0012993967393413186 | new best model!\n",
            "epoch 202 | validation loss: 0.0012994447024539113\n",
            "epoch 203 | validation loss: 0.0012860812712460756 | new best model!\n",
            "epoch 204 | validation loss: 0.0012794603244401515 | new best model!\n",
            "epoch 205 | validation loss: 0.0012735166819766164 | new best model!\n",
            "epoch 206 | validation loss: 0.0012619249755516648 | new best model!\n",
            "epoch 207 | validation loss: 0.0012506679049693048 | new best model!\n",
            "epoch 208 | validation loss: 0.0012551823747344315\n",
            "epoch 209 | validation loss: 0.0012331517646089196 | new best model!\n",
            "epoch 210 | validation loss: 0.0012441925355233252\n",
            "epoch 211 | validation loss: 0.0012188950786367059 | new best model!\n",
            "epoch 212 | validation loss: 0.0012135980068705976 | new best model!\n",
            "epoch 213 | validation loss: 0.001215438824146986\n",
            "epoch 214 | validation loss: 0.0011972427018918097 | new best model!\n",
            "epoch 215 | validation loss: 0.001194987038616091 | new best model!\n",
            "epoch 216 | validation loss: 0.0011835132609121501 | new best model!\n",
            "epoch 217 | validation loss: 0.001177125668618828 | new best model!\n",
            "epoch 218 | validation loss: 0.0011762313661165535 | new best model!\n",
            "epoch 219 | validation loss: 0.0011608900967985392 | new best model!\n",
            "epoch 220 | validation loss: 0.0011635335395112634\n",
            "epoch 221 | validation loss: 0.0011477232910692692 | new best model!\n",
            "epoch 222 | validation loss: 0.0011503707501105964\n",
            "epoch 223 | validation loss: 0.0011341957724653184 | new best model!\n",
            "epoch 224 | validation loss: 0.001138930965680629\n",
            "epoch 225 | validation loss: 0.0011230749660171568 | new best model!\n",
            "epoch 226 | validation loss: 0.0011159275891259313 | new best model!\n",
            "epoch 227 | validation loss: 0.001118150190450251\n",
            "epoch 228 | validation loss: 0.001102841692045331 | new best model!\n",
            "epoch 229 | validation loss: 0.001104415045119822\n",
            "epoch 230 | validation loss: 0.00109068863093853 | new best model!\n",
            "epoch 231 | validation loss: 0.001093095343094319\n",
            "epoch 232 | validation loss: 0.0010779117001220584 | new best model!\n",
            "epoch 233 | validation loss: 0.0010774655966088176 | new best model!\n",
            "epoch 234 | validation loss: 0.0010692495852708817 | new best model!\n",
            "epoch 235 | validation loss: 0.0010604769922792912 | new best model!\n",
            "epoch 236 | validation loss: 0.0010610475146677345\n",
            "epoch 237 | validation loss: 0.0010506036633159965 | new best model!\n",
            "epoch 238 | validation loss: 0.0010477334435563534 | new best model!\n",
            "epoch 239 | validation loss: 0.0010427366360090673 | new best model!\n",
            "epoch 240 | validation loss: 0.0010340227163396776 | new best model!\n",
            "epoch 241 | validation loss: 0.0010290011414326727 | new best model!\n",
            "epoch 242 | validation loss: 0.0010242075368296355 | new best model!\n",
            "epoch 243 | validation loss: 0.0010193103516940027 | new best model!\n",
            "epoch 244 | validation loss: 0.0010122636740561575 | new best model!\n",
            "epoch 245 | validation loss: 0.001011362619465217 | new best model!\n",
            "epoch 246 | validation loss: 0.0010070293792523444 | new best model!\n",
            "epoch 247 | validation loss: 0.0009977788722608238 | new best model!\n",
            "epoch 248 | validation loss: 0.001000957505311817\n",
            "epoch 249 | validation loss: 0.000985967431915924 | new best model!\n",
            "epoch 250 | validation loss: 0.0009861535218078643\n",
            "epoch 251 | validation loss: 0.0009762489644344896 | new best model!\n",
            "epoch 252 | validation loss: 0.00097222242038697 | new best model!\n",
            "epoch 253 | validation loss: 0.0009704696130938828 | new best model!\n",
            "epoch 254 | validation loss: 0.0009618470212444663 | new best model!\n",
            "epoch 255 | validation loss: 0.0009656696056481451\n",
            "epoch 256 | validation loss: 0.0009529935196042061 | new best model!\n",
            "epoch 257 | validation loss: 0.0009554414136800915\n",
            "epoch 258 | validation loss: 0.0009437537228222936 | new best model!\n",
            "epoch 259 | validation loss: 0.0009476275008637458\n",
            "epoch 260 | validation loss: 0.0009360862313769758 | new best model!\n",
            "epoch 261 | validation loss: 0.0009321098914369941 | new best model!\n",
            "epoch 262 | validation loss: 0.0009329282329417765\n",
            "epoch 263 | validation loss: 0.0009235198376700282 | new best model!\n",
            "epoch 264 | validation loss: 0.0009210565185640007 | new best model!\n",
            "epoch 265 | validation loss: 0.00091554009122774 | new best model!\n",
            "epoch 266 | validation loss: 0.0009129653917625546 | new best model!\n",
            "epoch 267 | validation loss: 0.0009103014890570194 | new best model!\n",
            "epoch 268 | validation loss: 0.0009043721365742385 | new best model!\n",
            "epoch 269 | validation loss: 0.0009024192986544222 | new best model!\n",
            "epoch 270 | validation loss: 0.0008974320953711867 | new best model!\n",
            "epoch 271 | validation loss: 0.0008947166497819126 | new best model!\n",
            "epoch 272 | validation loss: 0.0008878078660927713 | new best model!\n",
            "epoch 273 | validation loss: 0.0008880987588781863\n",
            "epoch 274 | validation loss: 0.0008815040928311646 | new best model!\n",
            "epoch 275 | validation loss: 0.0008781061333138496 | new best model!\n",
            "epoch 276 | validation loss: 0.0008750690030865371 | new best model!\n",
            "epoch 277 | validation loss: 0.0008703067142050713 | new best model!\n",
            "epoch 278 | validation loss: 0.0008707108499947935\n",
            "epoch 279 | validation loss: 0.0008631091332063079 | new best model!\n",
            "epoch 280 | validation loss: 0.0008637811406515539\n",
            "epoch 281 | validation loss: 0.0008569192723371089 | new best model!\n",
            "epoch 282 | validation loss: 0.0008550227794330567 | new best model!\n",
            "epoch 283 | validation loss: 0.0008538480324205011 | new best model!\n",
            "epoch 284 | validation loss: 0.0008463836275041103 | new best model!\n",
            "epoch 285 | validation loss: 0.0008449647575616837 | new best model!\n",
            "epoch 286 | validation loss: 0.0008405762200709432 | new best model!\n",
            "epoch 287 | validation loss: 0.0008375253819394857 | new best model!\n",
            "epoch 288 | validation loss: 0.000840710214106366\n",
            "epoch 289 | validation loss: 0.0008297560852952302 | new best model!\n",
            "epoch 290 | validation loss: 0.0008299254113808274\n",
            "epoch 291 | validation loss: 0.0008252939442172647 | new best model!\n",
            "epoch 292 | validation loss: 0.0008239743765443563 | new best model!\n",
            "epoch 293 | validation loss: 0.0008182220917660743 | new best model!\n",
            "epoch 294 | validation loss: 0.0008191168017219752\n",
            "epoch 295 | validation loss: 0.0008132748189382255 | new best model!\n",
            "epoch 296 | validation loss: 0.000809382094303146 | new best model!\n",
            "epoch 297 | validation loss: 0.0008105930755846202\n",
            "epoch 298 | validation loss: 0.0008039588283281773 | new best model!\n",
            "epoch 299 | validation loss: 0.000803975883172825\n",
            "epoch 300 | validation loss: 0.0007974230975378305 | new best model!\n",
            "epoch 301 | validation loss: 0.0007991446473170072\n",
            "epoch 302 | validation loss: 0.0007923443627078086 | new best model!\n",
            "epoch 303 | validation loss: 0.0007896012102719396 | new best model!\n",
            "epoch 304 | validation loss: 0.0007861403573770076 | new best model!\n",
            "epoch 305 | validation loss: 0.0007871327397879213\n",
            "epoch 306 | validation loss: 0.0007807928195688874 | new best model!\n",
            "epoch 307 | validation loss: 0.0007791119860485196 | new best model!\n",
            "epoch 308 | validation loss: 0.0007758227293379605 | new best model!\n",
            "epoch 309 | validation loss: 0.0007729051576461643 | new best model!\n",
            "epoch 310 | validation loss: 0.0007749360520392656\n",
            "epoch 311 | validation loss: 0.0007724063761997968 | new best model!\n",
            "epoch 312 | validation loss: 0.0007724793977104127\n",
            "epoch 313 | validation loss: 0.0007667452446185052 | new best model!\n",
            "epoch 314 | validation loss: 0.0007635105575900525 | new best model!\n",
            "epoch 315 | validation loss: 0.000758059584768489 | new best model!\n",
            "epoch 316 | validation loss: 0.0007598211814183742\n",
            "epoch 317 | validation loss: 0.0007542128150817007 | new best model!\n",
            "epoch 318 | validation loss: 0.0007553589239250869\n",
            "epoch 319 | validation loss: 0.0007483437366317958 | new best model!\n",
            "epoch 320 | validation loss: 0.0007452252903021872 | new best model!\n",
            "epoch 321 | validation loss: 0.0007431951817125082 | new best model!\n",
            "epoch 322 | validation loss: 0.0007407645462080836 | new best model!\n",
            "epoch 323 | validation loss: 0.0007416729931719601\n",
            "epoch 324 | validation loss: 0.0007368078222498298 | new best model!\n",
            "epoch 325 | validation loss: 0.0007365354686044157 | new best model!\n",
            "epoch 326 | validation loss: 0.0007318916323129088 | new best model!\n",
            "epoch 327 | validation loss: 0.0007291003712452948 | new best model!\n",
            "epoch 328 | validation loss: 0.0007311319641303271\n",
            "epoch 329 | validation loss: 0.0007248033361975104 | new best model!\n",
            "epoch 330 | validation loss: 0.0007244938751682639 | new best model!\n",
            "epoch 331 | validation loss: 0.0007210093026515096 | new best model!\n",
            "epoch 332 | validation loss: 0.0007182431581895798 | new best model!\n",
            "epoch 333 | validation loss: 0.0007162086549215019 | new best model!\n",
            "epoch 334 | validation loss: 0.0007143256079871207 | new best model!\n",
            "epoch 335 | validation loss: 0.000712161767296493 | new best model!\n",
            "epoch 336 | validation loss: 0.0007102956587914377 | new best model!\n",
            "epoch 337 | validation loss: 0.0007075617322698236 | new best model!\n",
            "epoch 338 | validation loss: 0.0007065143436193466 | new best model!\n",
            "epoch 339 | validation loss: 0.0007034173759166151 | new best model!\n",
            "epoch 340 | validation loss: 0.0007020925986580551 | new best model!\n",
            "epoch 341 | validation loss: 0.000699973403243348 | new best model!\n",
            "epoch 342 | validation loss: 0.0006976547883823514 | new best model!\n",
            "epoch 343 | validation loss: 0.0006991812260821462\n",
            "epoch 344 | validation loss: 0.000698749820003286\n",
            "epoch 345 | validation loss: 0.0007019085751380771\n",
            "epoch 346 | validation loss: 0.0006966408400330693 | new best model!\n",
            "epoch 347 | validation loss: 0.0006896166014485061 | new best model!\n",
            "epoch 348 | validation loss: 0.0006866064795758575 | new best model!\n",
            "epoch 349 | validation loss: 0.0006870694051031023\n",
            "epoch 350 | validation loss: 0.0006934438133612275\n",
            "epoch 351 | validation loss: 0.0006868890195619315\n",
            "epoch 352 | validation loss: 0.0006872348894830793\n",
            "epoch 353 | validation loss: 0.0006864536262582988 | new best model!\n",
            "epoch 354 | validation loss: 0.0006855942774564028 | new best model!\n",
            "epoch 355 | validation loss: 0.0006756417860742658 | new best model!\n",
            "epoch 356 | validation loss: 0.0006784067081753165\n",
            "epoch 357 | validation loss: 0.0006740187818650156 | new best model!\n",
            "epoch 358 | validation loss: 0.0006702269311062992 | new best model!\n",
            "epoch 359 | validation loss: 0.0006679202488157898 | new best model!\n",
            "epoch 360 | validation loss: 0.0006688690336886793\n",
            "epoch 361 | validation loss: 0.000670162815367803\n",
            "epoch 362 | validation loss: 0.0006733221525792032\n",
            "epoch 363 | validation loss: 0.0006654102762695402 | new best model!\n",
            "epoch 364 | validation loss: 0.0006591404089704156 | new best model!\n",
            "epoch 365 | validation loss: 0.0006583014910575002 | new best model!\n",
            "epoch 366 | validation loss: 0.0006573693244718015 | new best model!\n",
            "epoch 367 | validation loss: 0.0006573194114025682 | new best model!\n",
            "epoch 368 | validation loss: 0.0006567722011823207 | new best model!\n",
            "epoch 369 | validation loss: 0.0006516056309919804 | new best model!\n",
            "epoch 370 | validation loss: 0.0006503389740828425 | new best model!\n",
            "epoch 371 | validation loss: 0.0006483471079263836 | new best model!\n",
            "epoch 372 | validation loss: 0.000646977947326377 | new best model!\n",
            "epoch 373 | validation loss: 0.0006459730211645365 | new best model!\n",
            "epoch 374 | validation loss: 0.0006448854983318597 | new best model!\n",
            "epoch 375 | validation loss: 0.0006424127204809338 | new best model!\n",
            "epoch 376 | validation loss: 0.0006417238910216838 | new best model!\n",
            "epoch 377 | validation loss: 0.0006405714666470885 | new best model!\n",
            "epoch 378 | validation loss: 0.0006380860286299139 | new best model!\n",
            "epoch 379 | validation loss: 0.0006366365123540163 | new best model!\n",
            "epoch 380 | validation loss: 0.0006353229691740125 | new best model!\n",
            "epoch 381 | validation loss: 0.0006343327695503831 | new best model!\n",
            "epoch 382 | validation loss: 0.0006354978104354814\n",
            "epoch 383 | validation loss: 0.0006323333946056664 | new best model!\n",
            "epoch 384 | validation loss: 0.00063650484662503\n",
            "epoch 385 | validation loss: 0.0006320418906398118 | new best model!\n",
            "epoch 386 | validation loss: 0.0006306712894001976 | new best model!\n",
            "epoch 387 | validation loss: 0.0006264535622904077 | new best model!\n",
            "epoch 388 | validation loss: 0.0006275778578128666\n",
            "epoch 389 | validation loss: 0.0006263713876251131 | new best model!\n",
            "epoch 390 | validation loss: 0.0006241024821065366 | new best model!\n",
            "epoch 391 | validation loss: 0.0006212075386429206 | new best model!\n",
            "epoch 392 | validation loss: 0.0006203323428053409 | new best model!\n",
            "epoch 393 | validation loss: 0.0006192309374455363 | new best model!\n",
            "epoch 394 | validation loss: 0.0006182149227242917 | new best model!\n",
            "epoch 395 | validation loss: 0.0006176917668199167 | new best model!\n",
            "epoch 396 | validation loss: 0.0006169432890601456 | new best model!\n",
            "epoch 397 | validation loss: 0.0006152502028271556 | new best model!\n",
            "epoch 398 | validation loss: 0.0006142765778349712 | new best model!\n",
            "epoch 399 | validation loss: 0.0006124332285253331 | new best model!\n",
            "epoch 400 | validation loss: 0.0006114356801845133 | new best model!\n",
            "epoch 401 | validation loss: 0.000613983444054611\n",
            "epoch 402 | validation loss: 0.0006180088821565732\n",
            "epoch 403 | validation loss: 0.0006139175966382027\n",
            "epoch 404 | validation loss: 0.0006152486894279718\n",
            "epoch 405 | validation loss: 0.0006081291212467477 | new best model!\n",
            "epoch 406 | validation loss: 0.0006178853218443692\n",
            "epoch 407 | validation loss: 0.0006144345388747752\n",
            "epoch 408 | validation loss: 0.0006081510509829968\n",
            "epoch 409 | validation loss: 0.0006016779952915385 | new best model!\n",
            "epoch 410 | validation loss: 0.0006087462825234979\n",
            "epoch 411 | validation loss: 0.000603337844950147\n",
            "epoch 412 | validation loss: 0.0006023809255566448\n",
            "epoch 413 | validation loss: 0.0005987712502246723 | new best model!\n",
            "epoch 414 | validation loss: 0.0005987391050439328 | new best model!\n",
            "epoch 415 | validation loss: 0.0005957571411272511 | new best model!\n",
            "epoch 416 | validation loss: 0.000595740755670704 | new best model!\n",
            "epoch 417 | validation loss: 0.0005940734554314986 | new best model!\n",
            "epoch 418 | validation loss: 0.0005926458834437653 | new best model!\n",
            "epoch 419 | validation loss: 0.0005941278068348765\n",
            "epoch 420 | validation loss: 0.0005911885673413053 | new best model!\n",
            "epoch 421 | validation loss: 0.0005928606406087056\n",
            "epoch 422 | validation loss: 0.0005893946217838675 | new best model!\n",
            "epoch 423 | validation loss: 0.000591416610404849\n",
            "epoch 424 | validation loss: 0.00058832234935835 | new best model!\n",
            "epoch 425 | validation loss: 0.0005874199123354629 | new best model!\n",
            "epoch 426 | validation loss: 0.0005855962226632982 | new best model!\n",
            "epoch 427 | validation loss: 0.000585759655223228\n",
            "epoch 428 | validation loss: 0.0005836414347868413 | new best model!\n",
            "epoch 429 | validation loss: 0.0005835219199070707 | new best model!\n",
            "epoch 430 | validation loss: 0.0005848916625836864\n",
            "epoch 431 | validation loss: 0.0005850732559338212\n",
            "epoch 432 | validation loss: 0.0005881621182197705\n",
            "epoch 433 | validation loss: 0.0005794767057523131 | new best model!\n",
            "epoch 434 | validation loss: 0.000581450411118567\n",
            "epoch 435 | validation loss: 0.000580752981477417\n",
            "epoch 436 | validation loss: 0.0005778079648735002 | new best model!\n",
            "epoch 437 | validation loss: 0.0005760290805483237 | new best model!\n",
            "epoch 438 | validation loss: 0.0005769420822616667\n",
            "epoch 439 | validation loss: 0.0005803261592518538\n",
            "epoch 440 | validation loss: 0.0005799910722998902\n",
            "epoch 441 | validation loss: 0.0005750220152549446 | new best model!\n",
            "epoch 442 | validation loss: 0.0005741677305195481 | new best model!\n",
            "epoch 443 | validation loss: 0.0005718618776882067 | new best model!\n",
            "epoch 444 | validation loss: 0.0005708991084247828 | new best model!\n",
            "epoch 445 | validation loss: 0.0005710567202186212\n",
            "epoch 446 | validation loss: 0.0005730512639274821\n",
            "epoch 447 | validation loss: 0.0005699783505406231 | new best model!\n",
            "epoch 448 | validation loss: 0.0005679769965354353 | new best model!\n",
            "epoch 449 | validation loss: 0.0005692736740456894\n",
            "epoch 450 | validation loss: 0.0005673970736097544 | new best model!\n",
            "epoch 451 | validation loss: 0.0005691937112715095\n",
            "epoch 452 | validation loss: 0.0005661221512127668 | new best model!\n",
            "epoch 453 | validation loss: 0.0005655381391989067 | new best model!\n",
            "epoch 454 | validation loss: 0.0005655305430991575 | new best model!\n",
            "epoch 455 | validation loss: 0.0005662693583872169\n",
            "epoch 456 | validation loss: 0.0005620400625048205 | new best model!\n",
            "epoch 457 | validation loss: 0.0005621296586468816\n",
            "epoch 458 | validation loss: 0.0005611016676994041 | new best model!\n",
            "epoch 459 | validation loss: 0.0005647779762512073\n",
            "epoch 460 | validation loss: 0.0005632905522361398\n",
            "epoch 461 | validation loss: 0.0005664125928888097\n",
            "epoch 462 | validation loss: 0.0005604587349807844 | new best model!\n",
            "epoch 463 | validation loss: 0.000558896063012071 | new best model!\n",
            "epoch 464 | validation loss: 0.0005568622727878392 | new best model!\n",
            "epoch 465 | validation loss: 0.0005555948009714484 | new best model!\n",
            "epoch 466 | validation loss: 0.0005550520872930065 | new best model!\n",
            "epoch 467 | validation loss: 0.0005567121406784281\n",
            "epoch 468 | validation loss: 0.0005634624831145629\n",
            "epoch 469 | validation loss: 0.0005624330224236473\n",
            "epoch 470 | validation loss: 0.0005671491817338392\n",
            "epoch 471 | validation loss: 0.0005639683513436466\n",
            "epoch 472 | validation loss: 0.0005671825492754579\n",
            "epoch 473 | validation loss: 0.0005533535440918058 | new best model!\n",
            "epoch 474 | validation loss: 0.0005536622484214604\n",
            "epoch 475 | validation loss: 0.0005580262950388715\n",
            "epoch 476 | validation loss: 0.0005594323738478124\n",
            "epoch 477 | validation loss: 0.0005606973427347839\n",
            "epoch 478 | validation loss: 0.0005683937488356605\n",
            "epoch 479 | validation loss: 0.00055335157958325 | new best model!\n",
            "epoch 480 | validation loss: 0.00055997449089773\n",
            "epoch 481 | validation loss: 0.0005515263474080712 | new best model!\n",
            "epoch 482 | validation loss: 0.0005506495217559859 | new best model!\n",
            "epoch 483 | validation loss: 0.0005473002383951098 | new best model!\n",
            "epoch 484 | validation loss: 0.0005486731679411605\n",
            "epoch 485 | validation loss: 0.0005438981170300394 | new best model!\n",
            "epoch 486 | validation loss: 0.0005465102585731074\n",
            "epoch 487 | validation loss: 0.0005443716654554009\n",
            "epoch 488 | validation loss: 0.0005467696319101378\n",
            "epoch 489 | validation loss: 0.0005425998097052798 | new best model!\n",
            "epoch 490 | validation loss: 0.0005421251407824457 | new best model!\n",
            "epoch 491 | validation loss: 0.0005397835629992187 | new best model!\n",
            "epoch 492 | validation loss: 0.0005393254687078297 | new best model!\n",
            "epoch 493 | validation loss: 0.0005383090319810435 | new best model!\n",
            "epoch 494 | validation loss: 0.0005384727846831083\n",
            "epoch 495 | validation loss: 0.0005382559902500361 | new best model!\n",
            "epoch 496 | validation loss: 0.0005380268848966807 | new best model!\n",
            "epoch 497 | validation loss: 0.0005362117226468399 | new best model!\n",
            "epoch 498 | validation loss: 0.0005353828018996865 | new best model!\n",
            "epoch 499 | validation loss: 0.0005366219411371276\n",
            "epoch 500 | validation loss: 0.0005359855422284454\n",
            "epoch 501 | validation loss: 0.0005359055940061808\n",
            "epoch 502 | validation loss: 0.0005400239897426218\n",
            "epoch 503 | validation loss: 0.0005328011902747676 | new best model!\n",
            "epoch 504 | validation loss: 0.0005348703125491738\n",
            "epoch 505 | validation loss: 0.0005329676641849801\n",
            "epoch 506 | validation loss: 0.0005309830012265593 | new best model!\n",
            "epoch 507 | validation loss: 0.0005307703831931576 | new best model!\n",
            "epoch 508 | validation loss: 0.0005325815873220563\n",
            "epoch 509 | validation loss: 0.0005317683680914342\n",
            "epoch 510 | validation loss: 0.0005316011229297146\n",
            "epoch 511 | validation loss: 0.0005281364283291623 | new best model!\n",
            "epoch 512 | validation loss: 0.0005284070939524099\n",
            "epoch 513 | validation loss: 0.0005291185661917552\n",
            "epoch 514 | validation loss: 0.0005289255204843357\n",
            "epoch 515 | validation loss: 0.0005257692828308791 | new best model!\n",
            "epoch 516 | validation loss: 0.0005252635601209477 | new best model!\n",
            "epoch 517 | validation loss: 0.0005242035258561373 | new best model!\n",
            "epoch 518 | validation loss: 0.0005236270517343655 | new best model!\n",
            "epoch 519 | validation loss: 0.0005291173147270456\n",
            "epoch 520 | validation loss: 0.0005227935762377456 | new best model!\n",
            "epoch 521 | validation loss: 0.0005234563868725672\n",
            "epoch 522 | validation loss: 0.0005261415644781664\n",
            "epoch 523 | validation loss: 0.0005232347612036392\n",
            "epoch 524 | validation loss: 0.0005242032202659175\n",
            "epoch 525 | validation loss: 0.0005206059577176347 | new best model!\n",
            "epoch 526 | validation loss: 0.0005201630265219137 | new best model!\n",
            "epoch 527 | validation loss: 0.0005182427557883784 | new best model!\n",
            "epoch 528 | validation loss: 0.0005179858999326825 | new best model!\n",
            "epoch 529 | validation loss: 0.0005175398400751874 | new best model!\n",
            "epoch 530 | validation loss: 0.0005165305628906935 | new best model!\n",
            "epoch 531 | validation loss: 0.0005162388988537714 | new best model!\n",
            "epoch 532 | validation loss: 0.0005159806023584679 | new best model!\n",
            "epoch 533 | validation loss: 0.0005157090781722218 | new best model!\n",
            "epoch 534 | validation loss: 0.0005139620916452259 | new best model!\n",
            "epoch 535 | validation loss: 0.0005135145038366318 | new best model!\n",
            "epoch 536 | validation loss: 0.0005144270980963483\n",
            "epoch 537 | validation loss: 0.0005124450399307534 | new best model!\n",
            "epoch 538 | validation loss: 0.0005134049861226231\n",
            "epoch 539 | validation loss: 0.0005169392970856279\n",
            "epoch 540 | validation loss: 0.000510404264787212 | new best model!\n",
            "epoch 541 | validation loss: 0.0005114100204082206\n",
            "epoch 542 | validation loss: 0.0005113795195939019\n",
            "epoch 543 | validation loss: 0.0005093641520943493 | new best model!\n",
            "epoch 544 | validation loss: 0.0005094674415886402\n",
            "epoch 545 | validation loss: 0.0005094254011055455\n",
            "epoch 546 | validation loss: 0.0005082902207504958 | new best model!\n",
            "epoch 547 | validation loss: 0.0005076965317130089 | new best model!\n",
            "epoch 548 | validation loss: 0.0005067021556897089 | new best model!\n",
            "epoch 549 | validation loss: 0.0005066541925771162 | new best model!\n",
            "epoch 550 | validation loss: 0.0005054005014244467 | new best model!\n",
            "epoch 551 | validation loss: 0.0005070157203590497\n",
            "epoch 552 | validation loss: 0.000506590586155653\n",
            "epoch 553 | validation loss: 0.0005048483144491911 | new best model!\n",
            "epoch 554 | validation loss: 0.0005053119530202821\n",
            "epoch 555 | validation loss: 0.0005064968136139214\n",
            "epoch 556 | validation loss: 0.0005076437955722213\n",
            "epoch 557 | validation loss: 0.0005037328228354454 | new best model!\n",
            "epoch 558 | validation loss: 0.0005047753365943208\n",
            "epoch 559 | validation loss: 0.0005042646662332118\n",
            "epoch 560 | validation loss: 0.0005083976429887116\n",
            "epoch 561 | validation loss: 0.0005020131648052484 | new best model!\n",
            "epoch 562 | validation loss: 0.0005007771251257509 | new best model!\n",
            "epoch 563 | validation loss: 0.0004990908928448334 | new best model!\n",
            "epoch 564 | validation loss: 0.0004992933972971514\n",
            "epoch 565 | validation loss: 0.0004981195379514247 | new best model!\n",
            "epoch 566 | validation loss: 0.000497060886118561 | new best model!\n",
            "epoch 567 | validation loss: 0.0004981077945558354\n",
            "epoch 568 | validation loss: 0.0004973298346158117\n",
            "epoch 569 | validation loss: 0.0005010231834603474\n",
            "epoch 570 | validation loss: 0.0004952898452756926 | new best model!\n",
            "epoch 571 | validation loss: 0.0004961604427080601\n",
            "epoch 572 | validation loss: 0.0004959395591868088\n",
            "epoch 573 | validation loss: 0.000496638473123312\n",
            "epoch 574 | validation loss: 0.0004977357748430222\n",
            "epoch 575 | validation loss: 0.0004989668232155964\n",
            "epoch 576 | validation loss: 0.000492773688165471 | new best model!\n",
            "epoch 577 | validation loss: 0.0004935485630994663\n",
            "epoch 578 | validation loss: 0.0004924557142658159 | new best model!\n",
            "epoch 579 | validation loss: 0.0004920986102661118 | new best model!\n",
            "epoch 580 | validation loss: 0.0004927514819428325\n",
            "epoch 581 | validation loss: 0.0004910716379527003 | new best model!\n",
            "epoch 582 | validation loss: 0.0004899412160739303 | new best model!\n",
            "epoch 583 | validation loss: 0.0004889144765911624 | new best model!\n",
            "epoch 584 | validation loss: 0.0004893846344202757\n",
            "epoch 585 | validation loss: 0.0004894212906947359\n",
            "epoch 586 | validation loss: 0.0004888125986326486 | new best model!\n",
            "epoch 587 | validation loss: 0.0004900042695226148\n",
            "epoch 588 | validation loss: 0.0004868606338277459 | new best model!\n",
            "epoch 589 | validation loss: 0.0004881857748841867\n",
            "epoch 590 | validation loss: 0.00048807659186422825\n",
            "epoch 591 | validation loss: 0.00048815246555022895\n",
            "epoch 592 | validation loss: 0.0004886131646344438\n",
            "epoch 593 | validation loss: 0.00048813066678121686\n",
            "epoch 594 | validation loss: 0.00048570503713563085 | new best model!\n",
            "epoch 595 | validation loss: 0.0004833772109122947 | new best model!\n",
            "epoch 596 | validation loss: 0.00048337825865019113\n",
            "epoch 597 | validation loss: 0.00048355253238696605\n",
            "epoch 598 | validation loss: 0.0004860941116930917\n",
            "epoch 599 | validation loss: 0.0004823428316740319 | new best model!\n",
            "epoch 600 | validation loss: 0.000480888964375481 | new best model!\n",
            "epoch 601 | validation loss: 0.0004808683297596872 | new best model!\n",
            "epoch 602 | validation loss: 0.00048146261542569846\n",
            "epoch 603 | validation loss: 0.0004815273714484647\n",
            "epoch 604 | validation loss: 0.00048054342914838344 | new best model!\n",
            "epoch 605 | validation loss: 0.00047983940748963505 | new best model!\n",
            "epoch 606 | validation loss: 0.0004801346076419577\n",
            "epoch 607 | validation loss: 0.0004797664732905105 | new best model!\n",
            "epoch 608 | validation loss: 0.0004788873775396496 | new best model!\n",
            "epoch 609 | validation loss: 0.00047815007565077394 | new best model!\n",
            "epoch 610 | validation loss: 0.00047734966210555285 | new best model!\n",
            "epoch 611 | validation loss: 0.0004764150799019262 | new best model!\n",
            "epoch 612 | validation loss: 0.000475957480375655 | new best model!\n",
            "epoch 613 | validation loss: 0.0004765467601828277\n",
            "epoch 614 | validation loss: 0.0004764265177072957\n",
            "epoch 615 | validation loss: 0.0004756388225359842 | new best model!\n",
            "epoch 616 | validation loss: 0.0004745445621665567 | new best model!\n",
            "epoch 617 | validation loss: 0.00047392303531523794 | new best model!\n",
            "epoch 618 | validation loss: 0.00047315754636656493 | new best model!\n",
            "epoch 619 | validation loss: 0.00047350347449537367\n",
            "epoch 620 | validation loss: 0.0004731931257992983\n",
            "epoch 621 | validation loss: 0.0004728378407889977 | new best model!\n",
            "epoch 622 | validation loss: 0.000471645689685829 | new best model!\n",
            "epoch 623 | validation loss: 0.0004740835865959525\n",
            "epoch 624 | validation loss: 0.000477229172247462\n",
            "epoch 625 | validation loss: 0.0004729593056254089\n",
            "epoch 626 | validation loss: 0.00047205897863022983\n",
            "epoch 627 | validation loss: 0.0004700605204561725 | new best model!\n",
            "epoch 628 | validation loss: 0.00046906789066269994 | new best model!\n",
            "epoch 629 | validation loss: 0.0004715645045507699\n",
            "epoch 630 | validation loss: 0.00046894729894120246 | new best model!\n",
            "epoch 631 | validation loss: 0.00046825726167298853 | new best model!\n",
            "epoch 632 | validation loss: 0.00046759293763898313 | new best model!\n",
            "epoch 633 | validation loss: 0.00046754314098507166 | new best model!\n",
            "epoch 634 | validation loss: 0.0004662352439481765 | new best model!\n",
            "epoch 635 | validation loss: 0.00046716300130356103\n",
            "epoch 636 | validation loss: 0.00046673629549331963\n",
            "epoch 637 | validation loss: 0.00046704850683454424\n",
            "epoch 638 | validation loss: 0.0004646629822673276 | new best model!\n",
            "epoch 639 | validation loss: 0.00046412451774813235 | new best model!\n",
            "epoch 640 | validation loss: 0.0004640505067072809 | new best model!\n",
            "epoch 641 | validation loss: 0.0004641704435925931\n",
            "epoch 642 | validation loss: 0.0004655897064367309\n",
            "epoch 643 | validation loss: 0.00046554482833016664\n",
            "epoch 644 | validation loss: 0.00046369787014555186 | new best model!\n",
            "epoch 645 | validation loss: 0.00046770815970376134\n",
            "epoch 646 | validation loss: 0.0004614308854797855 | new best model!\n",
            "epoch 647 | validation loss: 0.00046163015940692276\n",
            "epoch 648 | validation loss: 0.0004625003057299182\n",
            "epoch 649 | validation loss: 0.0004604680143529549 | new best model!\n",
            "epoch 650 | validation loss: 0.0004604190762620419 | new best model!\n",
            "epoch 651 | validation loss: 0.0004590923781506717 | new best model!\n",
            "epoch 652 | validation loss: 0.000461985488072969\n",
            "epoch 653 | validation loss: 0.00045947211037855595\n",
            "epoch 654 | validation loss: 0.00045823979598935694 | new best model!\n",
            "epoch 655 | validation loss: 0.0004580745444400236 | new best model!\n",
            "epoch 656 | validation loss: 0.00046570159611292183\n",
            "epoch 657 | validation loss: 0.00046038061555009335\n",
            "epoch 658 | validation loss: 0.0004607205337379128\n",
            "epoch 659 | validation loss: 0.00046322360867634416\n",
            "epoch 660 | validation loss: 0.0004581367247737944\n",
            "epoch 661 | validation loss: 0.00045500663691200316 | new best model!\n",
            "epoch 662 | validation loss: 0.0004547360440483317 | new best model!\n",
            "epoch 663 | validation loss: 0.00045511548523791134\n",
            "epoch 664 | validation loss: 0.00045498713734559715\n",
            "epoch 665 | validation loss: 0.0004546298732748255 | new best model!\n",
            "epoch 666 | validation loss: 0.0004542056849459186 | new best model!\n",
            "epoch 667 | validation loss: 0.00045500740816351026\n",
            "epoch 668 | validation loss: 0.0004524151881923899 | new best model!\n",
            "epoch 669 | validation loss: 0.0004521482333075255 | new best model!\n",
            "epoch 670 | validation loss: 0.00045251882693264633\n",
            "epoch 671 | validation loss: 0.0004520665534073487 | new best model!\n",
            "epoch 672 | validation loss: 0.00045202759793028235 | new best model!\n",
            "epoch 673 | validation loss: 0.0004598846717271954\n",
            "epoch 674 | validation loss: 0.00045451339974533767\n",
            "epoch 675 | validation loss: 0.00045773337478749454\n",
            "epoch 676 | validation loss: 0.0004505388787947595 | new best model!\n",
            "epoch 677 | validation loss: 0.0004485426616156474 | new best model!\n",
            "epoch 678 | validation loss: 0.00044867659744340926\n",
            "epoch 679 | validation loss: 0.0004497478366829455\n",
            "epoch 680 | validation loss: 0.0004609677707776427\n",
            "epoch 681 | validation loss: 0.00044801108015235513 | new best model!\n",
            "epoch 682 | validation loss: 0.00044952706957701594\n",
            "epoch 683 | validation loss: 0.00044910456927027553\n",
            "epoch 684 | validation loss: 0.00045749063428957015\n",
            "epoch 685 | validation loss: 0.0004612567281583324\n",
            "epoch 686 | validation loss: 0.00046533651766367257\n",
            "epoch 687 | validation loss: 0.0004493760643526912\n",
            "epoch 688 | validation loss: 0.00044505872938316315 | new best model!\n",
            "epoch 689 | validation loss: 0.00044413817522581667 | new best model!\n",
            "epoch 690 | validation loss: 0.0004432558489497751 | new best model!\n",
            "epoch 691 | validation loss: 0.0004444874939508736\n",
            "epoch 692 | validation loss: 0.0004434141592355445\n",
            "epoch 693 | validation loss: 0.00044412257557269186\n",
            "epoch 694 | validation loss: 0.00044229412742424756 | new best model!\n",
            "epoch 695 | validation loss: 0.00044202151184435934 | new best model!\n",
            "epoch 696 | validation loss: 0.0004406105726957321 | new best model!\n",
            "epoch 697 | validation loss: 0.0004407497472129762\n",
            "epoch 698 | validation loss: 0.0004399152530822903 | new best model!\n",
            "epoch 699 | validation loss: 0.0004401402111398056\n",
            "epoch 700 | validation loss: 0.00044001880451105535\n",
            "epoch 701 | validation loss: 0.0004404488572617993\n",
            "epoch 702 | validation loss: 0.0004410278197610751\n",
            "epoch 703 | validation loss: 0.00043785404704976827 | new best model!\n",
            "epoch 704 | validation loss: 0.0004386975197121501\n",
            "epoch 705 | validation loss: 0.0004380524915177375\n",
            "epoch 706 | validation loss: 0.00043808550981339067\n",
            "epoch 707 | validation loss: 0.000437437352957204 | new best model!\n",
            "epoch 708 | validation loss: 0.00043563180952332914 | new best model!\n",
            "epoch 709 | validation loss: 0.00043522199848666787 | new best model!\n",
            "epoch 710 | validation loss: 0.0004358371370472014\n",
            "epoch 711 | validation loss: 0.00043560641643125564\n",
            "epoch 712 | validation loss: 0.0004342271276982501 | new best model!\n",
            "epoch 713 | validation loss: 0.0004349121736595407\n",
            "epoch 714 | validation loss: 0.0004339337901910767 | new best model!\n",
            "epoch 715 | validation loss: 0.0004346069763414562\n",
            "epoch 716 | validation loss: 0.0004334007971920073 | new best model!\n",
            "epoch 717 | validation loss: 0.00043335989175830036 | new best model!\n",
            "epoch 718 | validation loss: 0.00043254454794805497 | new best model!\n",
            "epoch 719 | validation loss: 0.0004318350984249264 | new best model!\n",
            "epoch 720 | validation loss: 0.0004374377313069999\n",
            "epoch 721 | validation loss: 0.00043485587229952216\n",
            "epoch 722 | validation loss: 0.00043386014294810593\n",
            "epoch 723 | validation loss: 0.0004329212388256565\n",
            "epoch 724 | validation loss: 0.000431490276241675 | new best model!\n",
            "epoch 725 | validation loss: 0.0004299945430830121 | new best model!\n",
            "epoch 726 | validation loss: 0.00043215614277869463\n",
            "epoch 727 | validation loss: 0.0004290915239835158 | new best model!\n",
            "epoch 728 | validation loss: 0.0004290846118237823 | new best model!\n",
            "epoch 729 | validation loss: 0.0004290891520213336\n",
            "epoch 730 | validation loss: 0.0004299592546885833\n",
            "epoch 731 | validation loss: 0.00042929172923322767\n",
            "epoch 732 | validation loss: 0.00042657753510866314 | new best model!\n",
            "epoch 733 | validation loss: 0.0004273744852980599\n",
            "epoch 734 | validation loss: 0.00042762295925058424\n",
            "epoch 735 | validation loss: 0.00042715040035545826\n",
            "epoch 736 | validation loss: 0.00042538843990769237 | new best model!\n",
            "epoch 737 | validation loss: 0.00042823464900720865\n",
            "epoch 738 | validation loss: 0.00042622192995622754\n",
            "epoch 739 | validation loss: 0.00042756083712447435\n",
            "epoch 740 | validation loss: 0.0004272682563168928\n",
            "epoch 741 | validation loss: 0.0004235322121530771 | new best model!\n",
            "epoch 742 | validation loss: 0.0004262771108187735\n",
            "epoch 743 | validation loss: 0.0004236677195876837\n",
            "epoch 744 | validation loss: 0.0004231535131111741 | new best model!\n",
            "epoch 745 | validation loss: 0.0004222356074023992 | new best model!\n",
            "epoch 746 | validation loss: 0.00042192703403998166 | new best model!\n",
            "epoch 747 | validation loss: 0.00042400238453410566\n",
            "epoch 748 | validation loss: 0.0004301226872485131\n",
            "epoch 749 | validation loss: 0.00042739443597383797\n",
            "epoch 750 | validation loss: 0.0004218376852804795 | new best model!\n",
            "epoch 751 | validation loss: 0.00042015619692392647 | new best model!\n",
            "epoch 752 | validation loss: 0.00041975588828790933 | new best model!\n",
            "epoch 753 | validation loss: 0.00041959434747695923 | new best model!\n",
            "epoch 754 | validation loss: 0.0004191222396912053 | new best model!\n",
            "epoch 755 | validation loss: 0.0004192771448288113\n",
            "epoch 756 | validation loss: 0.0004183435667073354 | new best model!\n",
            "epoch 757 | validation loss: 0.00041748206422198564 | new best model!\n",
            "epoch 758 | validation loss: 0.0004181870608590543\n",
            "epoch 759 | validation loss: 0.00041847956890705973\n",
            "epoch 760 | validation loss: 0.00041737065475899726 | new best model!\n",
            "epoch 761 | validation loss: 0.00041628468898124993 | new best model!\n",
            "epoch 762 | validation loss: 0.00041858268377836794\n",
            "epoch 763 | validation loss: 0.0004159378295298666 | new best model!\n",
            "epoch 764 | validation loss: 0.0004158233932685107 | new best model!\n",
            "epoch 765 | validation loss: 0.0004161870456300676\n",
            "epoch 766 | validation loss: 0.00041501957457512617 | new best model!\n",
            "epoch 767 | validation loss: 0.0004144751583226025 | new best model!\n",
            "epoch 768 | validation loss: 0.00041420945490244776 | new best model!\n",
            "epoch 769 | validation loss: 0.00041337544098496437 | new best model!\n",
            "epoch 770 | validation loss: 0.0004129481385461986 | new best model!\n",
            "epoch 771 | validation loss: 0.00042054717778228223\n",
            "epoch 772 | validation loss: 0.00042039564868900925\n",
            "epoch 773 | validation loss: 0.00041213526856154203 | new best model!\n",
            "epoch 774 | validation loss: 0.0004146963619859889\n",
            "epoch 775 | validation loss: 0.00041668581252451986\n",
            "epoch 776 | validation loss: 0.0004145135753788054\n",
            "epoch 777 | validation loss: 0.00041750079253688455\n",
            "epoch 778 | validation loss: 0.0004243889561621472\n",
            "epoch 779 | validation loss: 0.0004234582738718018\n",
            "epoch 780 | validation loss: 0.0004093903407920152 | new best model!\n",
            "epoch 781 | validation loss: 0.0004099743964616209\n",
            "epoch 782 | validation loss: 0.0004136573406867683\n",
            "epoch 783 | validation loss: 0.0004092148446943611 | new best model!\n",
            "epoch 784 | validation loss: 0.0004082810482941568 | new best model!\n",
            "epoch 785 | validation loss: 0.00040984887164086103\n",
            "epoch 786 | validation loss: 0.00041418051114305854\n",
            "epoch 787 | validation loss: 0.0004103581450181082\n",
            "epoch 788 | validation loss: 0.0004078848287463188 | new best model!\n",
            "epoch 789 | validation loss: 0.0004080594808328897\n",
            "epoch 790 | validation loss: 0.0004107854329049587\n",
            "epoch 791 | validation loss: 0.0004115593619644642\n",
            "epoch 792 | validation loss: 0.0004093832249054685\n",
            "epoch 793 | validation loss: 0.00041243675514124334\n",
            "epoch 794 | validation loss: 0.00040523652569390833 | new best model!\n",
            "epoch 795 | validation loss: 0.00040539940528105944\n",
            "epoch 796 | validation loss: 0.00040471190004609525 | new best model!\n",
            "epoch 797 | validation loss: 0.00040625303518027067\n",
            "epoch 798 | validation loss: 0.0004040258063469082 | new best model!\n",
            "epoch 799 | validation loss: 0.00040361106221098453 | new best model!\n",
            "epoch 800 | validation loss: 0.00040417791751679033\n",
            "epoch 801 | validation loss: 0.00040388280467595905\n",
            "epoch 802 | validation loss: 0.00040865421760827303\n",
            "epoch 803 | validation loss: 0.00040365662425756454\n",
            "epoch 804 | validation loss: 0.00040235757478512824 | new best model!\n",
            "epoch 805 | validation loss: 0.00040941602492239326\n",
            "epoch 806 | validation loss: 0.0004045164241688326\n",
            "epoch 807 | validation loss: 0.00040099081525113434 | new best model!\n",
            "epoch 808 | validation loss: 0.0004003375070169568 | new best model!\n",
            "epoch 809 | validation loss: 0.0004048129776492715\n",
            "epoch 810 | validation loss: 0.00039988815842662007 | new best model!\n",
            "epoch 811 | validation loss: 0.0003994587023044005 | new best model!\n",
            "epoch 812 | validation loss: 0.0003991945704910904 | new best model!\n",
            "epoch 813 | validation loss: 0.000399586177081801\n",
            "epoch 814 | validation loss: 0.0003996062441729009\n",
            "epoch 815 | validation loss: 0.000399516400648281\n",
            "epoch 816 | validation loss: 0.00040179443021770567\n",
            "epoch 817 | validation loss: 0.0003996287705376744\n",
            "epoch 818 | validation loss: 0.0003973496059188619 | new best model!\n",
            "epoch 819 | validation loss: 0.00039881886914372444\n",
            "epoch 820 | validation loss: 0.0003980248875450343\n",
            "epoch 821 | validation loss: 0.0003972204722231254 | new best model!\n",
            "epoch 822 | validation loss: 0.00039655751606915146 | new best model!\n",
            "epoch 823 | validation loss: 0.0003963585040764883 | new best model!\n",
            "epoch 824 | validation loss: 0.00039799809746909887\n",
            "epoch 825 | validation loss: 0.0003962587215937674 | new best model!\n",
            "epoch 826 | validation loss: 0.00039447420567739755 | new best model!\n",
            "epoch 827 | validation loss: 0.000395231312722899\n",
            "epoch 828 | validation loss: 0.00039392392500303686 | new best model!\n",
            "epoch 829 | validation loss: 0.0003945091739296913\n",
            "epoch 830 | validation loss: 0.0003949343808926642\n",
            "epoch 831 | validation loss: 0.0003930238453904167 | new best model!\n",
            "epoch 832 | validation loss: 0.00039366127748508006\n",
            "epoch 833 | validation loss: 0.00039225383079610765 | new best model!\n",
            "epoch 834 | validation loss: 0.0003923010517610237\n",
            "epoch 835 | validation loss: 0.0003933181578759104\n",
            "epoch 836 | validation loss: 0.0003943214251194149\n",
            "epoch 837 | validation loss: 0.0003923109907191247\n",
            "epoch 838 | validation loss: 0.00039082295552361757 | new best model!\n",
            "epoch 839 | validation loss: 0.00039131264202296734\n",
            "epoch 840 | validation loss: 0.0003925989003619179\n",
            "epoch 841 | validation loss: 0.00039048961480148137 | new best model!\n",
            "epoch 842 | validation loss: 0.0003916958812624216\n",
            "epoch 843 | validation loss: 0.0003885290934704244 | new best model!\n",
            "epoch 844 | validation loss: 0.0003912161773769185\n",
            "epoch 845 | validation loss: 0.00039063063741195947\n",
            "epoch 846 | validation loss: 0.00039148388896137476\n",
            "epoch 847 | validation loss: 0.00039166984788607806\n",
            "epoch 848 | validation loss: 0.0003870846703648567 | new best model!\n",
            "epoch 849 | validation loss: 0.0003869640058837831 | new best model!\n",
            "epoch 850 | validation loss: 0.0003872698434861377\n",
            "epoch 851 | validation loss: 0.00038633926305919886 | new best model!\n",
            "epoch 852 | validation loss: 0.00038651927025057375\n",
            "epoch 853 | validation loss: 0.000386999876354821\n",
            "epoch 854 | validation loss: 0.00038610507908742875 | new best model!\n",
            "epoch 855 | validation loss: 0.00038973521441221237\n",
            "epoch 856 | validation loss: 0.00038859667256474495\n",
            "epoch 857 | validation loss: 0.0003871560766128823\n",
            "epoch 858 | validation loss: 0.00038699517608620226\n",
            "epoch 859 | validation loss: 0.0003907148784492165\n",
            "epoch 860 | validation loss: 0.0003880858130287379\n",
            "epoch 861 | validation loss: 0.0003852766822092235 | new best model!\n",
            "epoch 862 | validation loss: 0.000382849044399336 | new best model!\n",
            "epoch 863 | validation loss: 0.00038550196040887386\n",
            "epoch 864 | validation loss: 0.0003845541941700503\n",
            "epoch 865 | validation loss: 0.0003839149867417291\n",
            "epoch 866 | validation loss: 0.00038219470297917724 | new best model!\n",
            "epoch 867 | validation loss: 0.0003812795475823805 | new best model!\n",
            "epoch 868 | validation loss: 0.0003812140930676833 | new best model!\n",
            "epoch 869 | validation loss: 0.0003815343079622835\n",
            "epoch 870 | validation loss: 0.0003810440393863246 | new best model!\n",
            "epoch 871 | validation loss: 0.00038028469134587795 | new best model!\n",
            "epoch 872 | validation loss: 0.00038222564035095274\n",
            "epoch 873 | validation loss: 0.0003848597261821851\n",
            "epoch 874 | validation loss: 0.00038486327684950083\n",
            "epoch 875 | validation loss: 0.00037965037336107343 | new best model!\n",
            "epoch 876 | validation loss: 0.0003793320938711986 | new best model!\n",
            "epoch 877 | validation loss: 0.000381312143872492\n",
            "epoch 878 | validation loss: 0.0003778864920604974 | new best model!\n",
            "epoch 879 | validation loss: 0.00037761376006528735 | new best model!\n",
            "epoch 880 | validation loss: 0.0003770466864807531 | new best model!\n",
            "epoch 881 | validation loss: 0.00038081219827290624\n",
            "epoch 882 | validation loss: 0.0003820365818683058\n",
            "epoch 883 | validation loss: 0.0003844821476377547\n",
            "epoch 884 | validation loss: 0.00037702484405599535 | new best model!\n",
            "epoch 885 | validation loss: 0.0003781695559155196\n",
            "epoch 886 | validation loss: 0.0003778055979637429\n",
            "epoch 887 | validation loss: 0.00037498986057471484 | new best model!\n",
            "epoch 888 | validation loss: 0.0003762682026717812\n",
            "epoch 889 | validation loss: 0.0003765630681300536\n",
            "epoch 890 | validation loss: 0.0003829984925687313\n",
            "epoch 891 | validation loss: 0.00038769525417592376\n",
            "epoch 892 | validation loss: 0.0003753888449864462\n",
            "epoch 893 | validation loss: 0.00037509959656745195\n",
            "epoch 894 | validation loss: 0.0003786984889302403\n",
            "epoch 895 | validation loss: 0.00037715792132075876\n",
            "epoch 896 | validation loss: 0.0003734468627953902 | new best model!\n",
            "epoch 897 | validation loss: 0.0003763189015444368\n",
            "epoch 898 | validation loss: 0.00037349936610553414\n",
            "epoch 899 | validation loss: 0.00037644912663381547\n",
            "epoch 900 | validation loss: 0.00037383593735285103\n",
            "epoch 901 | validation loss: 0.000372619615518488 | new best model!\n",
            "epoch 902 | validation loss: 0.0003780779370572418\n",
            "epoch 903 | validation loss: 0.0003833358350675553\n",
            "epoch 904 | validation loss: 0.00038986263098195195\n",
            "epoch 905 | validation loss: 0.0003891585365636274\n",
            "epoch 906 | validation loss: 0.00037338836409617215\n",
            "epoch 907 | validation loss: 0.0003750192263396457\n",
            "epoch 908 | validation loss: 0.0003870393557008356\n",
            "epoch 909 | validation loss: 0.0004000491462647915\n",
            "epoch 910 | validation loss: 0.00038051942829042673\n",
            "epoch 911 | validation loss: 0.00037285972211975604\n",
            "epoch 912 | validation loss: 0.0003688875731313601 | new best model!\n",
            "epoch 913 | validation loss: 0.0003717819490702823\n",
            "epoch 914 | validation loss: 0.0003760986728593707\n",
            "epoch 915 | validation loss: 0.0003698779328260571\n",
            "epoch 916 | validation loss: 0.0003732146433321759\n",
            "epoch 917 | validation loss: 0.0003746979491552338\n",
            "epoch 918 | validation loss: 0.00037287491431925446\n",
            "epoch 919 | validation loss: 0.00036857907252851874 | new best model!\n",
            "epoch 920 | validation loss: 0.00036663793434854597 | new best model!\n",
            "epoch 921 | validation loss: 0.0003695408668136224\n",
            "epoch 922 | validation loss: 0.0003674315958051011\n",
            "epoch 923 | validation loss: 0.00036829755117651075\n",
            "epoch 924 | validation loss: 0.0003655780747067183 | new best model!\n",
            "epoch 925 | validation loss: 0.00036742762313224375\n",
            "epoch 926 | validation loss: 0.00036955252289772034\n",
            "epoch 927 | validation loss: 0.00036568957148119807\n",
            "epoch 928 | validation loss: 0.0003646498662419617 | new best model!\n",
            "epoch 929 | validation loss: 0.00036409117456059903 | new best model!\n",
            "epoch 930 | validation loss: 0.0003636198380263522 | new best model!\n",
            "epoch 931 | validation loss: 0.00036472646752372384\n",
            "epoch 932 | validation loss: 0.00036288828414399177 | new best model!\n",
            "epoch 933 | validation loss: 0.0003642103256424889\n",
            "epoch 934 | validation loss: 0.00036540674045681953\n",
            "epoch 935 | validation loss: 0.0003632292355177924\n",
            "epoch 936 | validation loss: 0.00036208811798132956 | new best model!\n",
            "epoch 937 | validation loss: 0.00036140774318482727 | new best model!\n",
            "epoch 938 | validation loss: 0.00036211046972312033\n",
            "epoch 939 | validation loss: 0.00036201358307152987\n",
            "epoch 940 | validation loss: 0.0003612766449805349 | new best model!\n",
            "epoch 941 | validation loss: 0.00036074996751267463 | new best model!\n",
            "epoch 942 | validation loss: 0.00036026314774062485 | new best model!\n",
            "epoch 943 | validation loss: 0.00036967621417716146\n",
            "epoch 944 | validation loss: 0.00037049812090117484\n",
            "epoch 945 | validation loss: 0.00036044386797584593\n",
            "epoch 946 | validation loss: 0.0003653612220659852\n",
            "epoch 947 | validation loss: 0.0003749719326151535\n",
            "epoch 948 | validation loss: 0.0003633389715105295\n",
            "epoch 949 | validation loss: 0.0003603212389862165\n",
            "epoch 950 | validation loss: 0.00035910107544623315 | new best model!\n",
            "epoch 951 | validation loss: 0.0003579824842745438 | new best model!\n",
            "epoch 952 | validation loss: 0.00035821975325234234\n",
            "epoch 953 | validation loss: 0.0003604058874770999\n",
            "epoch 954 | validation loss: 0.0003583876969059929\n",
            "epoch 955 | validation loss: 0.0003568826650734991 | new best model!\n",
            "epoch 956 | validation loss: 0.00035799639590550214\n",
            "epoch 957 | validation loss: 0.00035711498640011996\n",
            "epoch 958 | validation loss: 0.00035734994162339717\n",
            "epoch 959 | validation loss: 0.00036279963387642056\n",
            "epoch 960 | validation loss: 0.0003579792828531936\n",
            "epoch 961 | validation loss: 0.0003567258972907439 | new best model!\n",
            "epoch 962 | validation loss: 0.00036017593811266124\n",
            "epoch 963 | validation loss: 0.00036670584813691676\n",
            "epoch 964 | validation loss: 0.00036850012838840485\n",
            "epoch 965 | validation loss: 0.00036057586839888245\n",
            "epoch 966 | validation loss: 0.00035654134990181774 | new best model!\n",
            "epoch 967 | validation loss: 0.00035512099566403776 | new best model!\n",
            "epoch 968 | validation loss: 0.00035695503174792975\n",
            "epoch 969 | validation loss: 0.0003554474678821862\n",
            "epoch 970 | validation loss: 0.00035346562799531966 | new best model!\n",
            "epoch 971 | validation loss: 0.00035366897645872086\n",
            "epoch 972 | validation loss: 0.00035321824543643743 | new best model!\n",
            "epoch 973 | validation loss: 0.0003547793749021366\n",
            "epoch 974 | validation loss: 0.00035381496127229184\n",
            "epoch 975 | validation loss: 0.0003513501287670806 | new best model!\n",
            "epoch 976 | validation loss: 0.0003528720117174089\n",
            "epoch 977 | validation loss: 0.0003525744832586497\n",
            "epoch 978 | validation loss: 0.00035112521436531097 | new best model!\n",
            "epoch 979 | validation loss: 0.0003509055241011083 | new best model!\n",
            "epoch 980 | validation loss: 0.00035555083013605326\n",
            "epoch 981 | validation loss: 0.00035250016662757844\n",
            "epoch 982 | validation loss: 0.00035708815266843885\n",
            "epoch 983 | validation loss: 0.0003526466607581824\n",
            "epoch 984 | validation loss: 0.0003500301099848002 | new best model!\n",
            "epoch 985 | validation loss: 0.0003497230791253969 | new best model!\n",
            "epoch 986 | validation loss: 0.0003508047666400671\n",
            "epoch 987 | validation loss: 0.00035015041066799313\n",
            "epoch 988 | validation loss: 0.00034911664261016995 | new best model!\n",
            "epoch 989 | validation loss: 0.0003481991880107671 | new best model!\n",
            "epoch 990 | validation loss: 0.00034995388705283403\n",
            "epoch 991 | validation loss: 0.0003511845861794427\n",
            "epoch 992 | validation loss: 0.0003485118504613638\n",
            "epoch 993 | validation loss: 0.000347136941854842 | new best model!\n",
            "epoch 994 | validation loss: 0.00034691144537646323 | new best model!\n",
            "epoch 995 | validation loss: 0.0003501157771097496\n",
            "epoch 996 | validation loss: 0.00034685224818531424 | new best model!\n",
            "epoch 997 | validation loss: 0.0003507875371724367\n",
            "epoch 998 | validation loss: 0.0003556858719093725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 999 | validation loss: 0.0003466204507276416 | new best model!\n",
            "Average test error: 858.783447265625\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 | validation loss: 0.13189927861094475 | new best model!\n",
            "epoch 1 | validation loss: 0.12988174706697464 | new best model!\n",
            "epoch 2 | validation loss: 0.12792056426405907 | new best model!\n",
            "epoch 3 | validation loss: 0.12601033598184586 | new best model!\n",
            "epoch 4 | validation loss: 0.1241430938243866 | new best model!\n",
            "epoch 5 | validation loss: 0.1223304383456707 | new best model!\n",
            "epoch 6 | validation loss: 0.1205684207379818 | new best model!\n",
            "epoch 7 | validation loss: 0.11886004731059074 | new best model!\n",
            "epoch 8 | validation loss: 0.11720284074544907 | new best model!\n",
            "epoch 9 | validation loss: 0.11558663472533226 | new best model!\n",
            "epoch 10 | validation loss: 0.11401988938450813 | new best model!\n",
            "epoch 11 | validation loss: 0.11250251531600952 | new best model!\n",
            "epoch 12 | validation loss: 0.11102714017033577 | new best model!\n",
            "epoch 13 | validation loss: 0.10960221290588379 | new best model!\n",
            "epoch 14 | validation loss: 0.10821399465203285 | new best model!\n",
            "epoch 15 | validation loss: 0.10685612633824348 | new best model!\n",
            "epoch 16 | validation loss: 0.1055373102426529 | new best model!\n",
            "epoch 17 | validation loss: 0.1043228916823864 | new best model!\n",
            "epoch 18 | validation loss: 0.10314630344510078 | new best model!\n",
            "epoch 19 | validation loss: 0.10200202837586403 | new best model!\n",
            "epoch 20 | validation loss: 0.1009218879044056 | new best model!\n",
            "epoch 21 | validation loss: 0.09987176209688187 | new best model!\n",
            "epoch 22 | validation loss: 0.09884190559387207 | new best model!\n",
            "epoch 23 | validation loss: 0.09784138202667236 | new best model!\n",
            "epoch 24 | validation loss: 0.09686583280563354 | new best model!\n",
            "epoch 25 | validation loss: 0.09591761976480484 | new best model!\n",
            "epoch 26 | validation loss: 0.09498213604092598 | new best model!\n",
            "epoch 27 | validation loss: 0.09406974166631699 | new best model!\n",
            "epoch 28 | validation loss: 0.093182023614645 | new best model!\n",
            "epoch 29 | validation loss: 0.09232397004961967 | new best model!\n",
            "epoch 30 | validation loss: 0.0914766825735569 | new best model!\n",
            "epoch 31 | validation loss: 0.09064457938075066 | new best model!\n",
            "epoch 32 | validation loss: 0.08984533324837685 | new best model!\n",
            "epoch 33 | validation loss: 0.08904442936182022 | new best model!\n",
            "epoch 34 | validation loss: 0.08827771618962288 | new best model!\n",
            "epoch 35 | validation loss: 0.08753907680511475 | new best model!\n",
            "epoch 36 | validation loss: 0.08682120591402054 | new best model!\n",
            "epoch 37 | validation loss: 0.08611804246902466 | new best model!\n",
            "epoch 38 | validation loss: 0.08543151617050171 | new best model!\n",
            "epoch 39 | validation loss: 0.08475015684962273 | new best model!\n",
            "epoch 40 | validation loss: 0.08407264575362206 | new best model!\n",
            "epoch 41 | validation loss: 0.08340219780802727 | new best model!\n",
            "epoch 42 | validation loss: 0.08273956552147865 | new best model!\n",
            "epoch 43 | validation loss: 0.08208521082997322 | new best model!\n",
            "epoch 44 | validation loss: 0.081434216350317 | new best model!\n",
            "epoch 45 | validation loss: 0.08081639558076859 | new best model!\n",
            "epoch 46 | validation loss: 0.08019403740763664 | new best model!\n",
            "epoch 47 | validation loss: 0.07960109412670135 | new best model!\n",
            "epoch 48 | validation loss: 0.07899424806237221 | new best model!\n",
            "epoch 49 | validation loss: 0.07842203974723816 | new best model!\n",
            "epoch 50 | validation loss: 0.07785921916365623 | new best model!\n",
            "epoch 51 | validation loss: 0.07731007039546967 | new best model!\n",
            "epoch 52 | validation loss: 0.07678472250699997 | new best model!\n",
            "epoch 53 | validation loss: 0.07630787044763565 | new best model!\n",
            "epoch 54 | validation loss: 0.07587682083249092 | new best model!\n",
            "epoch 55 | validation loss: 0.0754559114575386 | new best model!\n",
            "epoch 56 | validation loss: 0.07503458112478256 | new best model!\n",
            "epoch 57 | validation loss: 0.07460839673876762 | new best model!\n",
            "epoch 58 | validation loss: 0.0741485096514225 | new best model!\n",
            "epoch 59 | validation loss: 0.07366687059402466 | new best model!\n",
            "epoch 60 | validation loss: 0.07311520725488663 | new best model!\n",
            "epoch 61 | validation loss: 0.07249446213245392 | new best model!\n",
            "epoch 62 | validation loss: 0.07175546139478683 | new best model!\n",
            "epoch 63 | validation loss: 0.0708775483071804 | new best model!\n",
            "epoch 64 | validation loss: 0.069799043238163 | new best model!\n",
            "epoch 65 | validation loss: 0.06850316561758518 | new best model!\n",
            "epoch 66 | validation loss: 0.06689678877592087 | new best model!\n",
            "epoch 67 | validation loss: 0.06495367176830769 | new best model!\n",
            "epoch 68 | validation loss: 0.06258886866271496 | new best model!\n",
            "epoch 69 | validation loss: 0.05973086319863796 | new best model!\n",
            "epoch 70 | validation loss: 0.05620971880853176 | new best model!\n",
            "epoch 71 | validation loss: 0.05224995315074921 | new best model!\n",
            "epoch 72 | validation loss: 0.048015689477324486 | new best model!\n",
            "epoch 73 | validation loss: 0.04378487356007099 | new best model!\n",
            "epoch 74 | validation loss: 0.03974827378988266 | new best model!\n",
            "epoch 75 | validation loss: 0.036021677777171135 | new best model!\n",
            "epoch 76 | validation loss: 0.03263299632817507 | new best model!\n",
            "epoch 77 | validation loss: 0.029537064023315907 | new best model!\n",
            "epoch 78 | validation loss: 0.026691566221415997 | new best model!\n",
            "epoch 79 | validation loss: 0.024060694500803947 | new best model!\n",
            "epoch 80 | validation loss: 0.021656900644302368 | new best model!\n",
            "epoch 81 | validation loss: 0.019481545314192772 | new best model!\n",
            "epoch 82 | validation loss: 0.01756152044981718 | new best model!\n",
            "epoch 83 | validation loss: 0.015804972499608994 | new best model!\n",
            "epoch 84 | validation loss: 0.014344323426485062 | new best model!\n",
            "epoch 85 | validation loss: 0.012840910349041224 | new best model!\n",
            "epoch 86 | validation loss: 0.011640035081654787 | new best model!\n",
            "epoch 87 | validation loss: 0.010580264497548342 | new best model!\n",
            "epoch 88 | validation loss: 0.009633210487663746 | new best model!\n",
            "epoch 89 | validation loss: 0.008885789196938276 | new best model!\n",
            "epoch 90 | validation loss: 0.008035611594095826 | new best model!\n",
            "epoch 91 | validation loss: 0.007761116838082671 | new best model!\n",
            "epoch 92 | validation loss: 0.006932821124792099 | new best model!\n",
            "epoch 93 | validation loss: 0.006648048525676131 | new best model!\n",
            "epoch 94 | validation loss: 0.0061924762558192015 | new best model!\n",
            "epoch 95 | validation loss: 0.005967870820313692 | new best model!\n",
            "epoch 96 | validation loss: 0.0054631829261779785 | new best model!\n",
            "epoch 97 | validation loss: 0.005458265542984009 | new best model!\n",
            "epoch 98 | validation loss: 0.005095980828627944 | new best model!\n",
            "epoch 99 | validation loss: 0.005067381309345365 | new best model!\n",
            "epoch 100 | validation loss: 0.004761767573654652 | new best model!\n",
            "epoch 101 | validation loss: 0.004580538370646536 | new best model!\n",
            "epoch 102 | validation loss: 0.0048093306832015514\n",
            "epoch 103 | validation loss: 0.004373213741928339 | new best model!\n",
            "epoch 104 | validation loss: 0.004388389992527664\n",
            "epoch 105 | validation loss: 0.004232505802065134 | new best model!\n",
            "epoch 106 | validation loss: 0.004261694732122123\n",
            "epoch 107 | validation loss: 0.004021246801130474 | new best model!\n",
            "epoch 108 | validation loss: 0.004161007585935295\n",
            "epoch 109 | validation loss: 0.003979304106906056 | new best model!\n",
            "epoch 110 | validation loss: 0.003852132009342313 | new best model!\n",
            "epoch 111 | validation loss: 0.003836797666735947 | new best model!\n",
            "epoch 112 | validation loss: 0.0037528069224208593 | new best model!\n",
            "epoch 113 | validation loss: 0.003922853269614279\n",
            "epoch 114 | validation loss: 0.0035717012360692024 | new best model!\n",
            "epoch 115 | validation loss: 0.003808571258559823\n",
            "epoch 116 | validation loss: 0.003498403006233275 | new best model!\n",
            "epoch 117 | validation loss: 0.0036263270303606987\n",
            "epoch 118 | validation loss: 0.003518084529787302\n",
            "epoch 119 | validation loss: 0.0035232165828347206\n",
            "epoch 120 | validation loss: 0.0034079491160809994 | new best model!\n",
            "epoch 121 | validation loss: 0.003458320163190365\n",
            "epoch 122 | validation loss: 0.003348476020619273 | new best model!\n",
            "epoch 123 | validation loss: 0.0033423450076952577 | new best model!\n",
            "epoch 124 | validation loss: 0.00326199596747756 | new best model!\n",
            "epoch 125 | validation loss: 0.0033085322938859463\n",
            "epoch 126 | validation loss: 0.0032153360079973936 | new best model!\n",
            "epoch 127 | validation loss: 0.0033080943394452333\n",
            "epoch 128 | validation loss: 0.0031808785861358047 | new best model!\n",
            "epoch 129 | validation loss: 0.0032061084639281034\n",
            "epoch 130 | validation loss: 0.003059884416870773 | new best model!\n",
            "epoch 131 | validation loss: 0.003125934745185077\n",
            "epoch 132 | validation loss: 0.0031227361178025603\n",
            "epoch 133 | validation loss: 0.0030550516676157713 | new best model!\n",
            "epoch 134 | validation loss: 0.0030532449018210173 | new best model!\n",
            "epoch 135 | validation loss: 0.002921069390140474 | new best model!\n",
            "epoch 136 | validation loss: 0.0030354122864082456\n",
            "epoch 137 | validation loss: 0.0028911365661770105 | new best model!\n",
            "epoch 138 | validation loss: 0.002933695912361145\n",
            "epoch 139 | validation loss: 0.0028334043454378843 | new best model!\n",
            "epoch 140 | validation loss: 0.002909073024056852\n",
            "epoch 141 | validation loss: 0.0028350717620924115\n",
            "epoch 142 | validation loss: 0.00283729110378772\n",
            "epoch 143 | validation loss: 0.002694641938433051 | new best model!\n",
            "epoch 144 | validation loss: 0.002762922551482916\n",
            "epoch 145 | validation loss: 0.0027024380397051573\n",
            "epoch 146 | validation loss: 0.002721325377933681\n",
            "epoch 147 | validation loss: 0.0026621571741998196 | new best model!\n",
            "epoch 148 | validation loss: 0.0026667516212910414\n",
            "epoch 149 | validation loss: 0.002654366078786552 | new best model!\n",
            "epoch 150 | validation loss: 0.0026349027175456285 | new best model!\n",
            "epoch 151 | validation loss: 0.0025989993009716272 | new best model!\n",
            "epoch 152 | validation loss: 0.002541086170822382 | new best model!\n",
            "epoch 153 | validation loss: 0.0025261130649596453 | new best model!\n",
            "epoch 154 | validation loss: 0.0025393691612407565\n",
            "epoch 155 | validation loss: 0.0024937064154073596 | new best model!\n",
            "epoch 156 | validation loss: 0.002436673268675804 | new best model!\n",
            "epoch 157 | validation loss: 0.0024631345877423882\n",
            "epoch 158 | validation loss: 0.002378209843300283 | new best model!\n",
            "epoch 159 | validation loss: 0.0024651710991747677\n",
            "epoch 160 | validation loss: 0.0023267230135388672 | new best model!\n",
            "epoch 161 | validation loss: 0.002379767771344632\n",
            "epoch 162 | validation loss: 0.002343994565308094\n",
            "epoch 163 | validation loss: 0.0022691144258715212 | new best model!\n",
            "epoch 164 | validation loss: 0.002362422354053706\n",
            "epoch 165 | validation loss: 0.002209940808825195 | new best model!\n",
            "epoch 166 | validation loss: 0.002274541126098484\n",
            "epoch 167 | validation loss: 0.0022086382377892733 | new best model!\n",
            "epoch 168 | validation loss: 0.0021800981485284865 | new best model!\n",
            "epoch 169 | validation loss: 0.002233837090898305\n",
            "epoch 170 | validation loss: 0.0021154267014935613 | new best model!\n",
            "epoch 171 | validation loss: 0.0022005762439221144\n",
            "epoch 172 | validation loss: 0.002084965060930699 | new best model!\n",
            "epoch 173 | validation loss: 0.0021096638520248234\n",
            "epoch 174 | validation loss: 0.002023213601205498 | new best model!\n",
            "epoch 175 | validation loss: 0.0021396914962679148\n",
            "epoch 176 | validation loss: 0.001991803990676999 | new best model!\n",
            "epoch 177 | validation loss: 0.0020462736720219254\n",
            "epoch 178 | validation loss: 0.0019864426576532423 | new best model!\n",
            "epoch 179 | validation loss: 0.0019481915514916182 | new best model!\n",
            "epoch 180 | validation loss: 0.002062411804217845\n",
            "epoch 181 | validation loss: 0.0018828345346264541 | new best model!\n",
            "epoch 182 | validation loss: 0.0019819694571197033\n",
            "epoch 183 | validation loss: 0.0018857643008232117\n",
            "epoch 184 | validation loss: 0.001956104126293212\n",
            "epoch 185 | validation loss: 0.0018452670192345977 | new best model!\n",
            "epoch 186 | validation loss: 0.0018834307556971908\n",
            "epoch 187 | validation loss: 0.0018543837359175086\n",
            "epoch 188 | validation loss: 0.001787428162060678 | new best model!\n",
            "epoch 189 | validation loss: 0.0018981185276061296\n",
            "epoch 190 | validation loss: 0.001742916356306523 | new best model!\n",
            "epoch 191 | validation loss: 0.001785776810720563\n",
            "epoch 192 | validation loss: 0.0017479329835623503\n",
            "epoch 193 | validation loss: 0.0017204483156092465 | new best model!\n",
            "epoch 194 | validation loss: 0.001732498756609857\n",
            "epoch 195 | validation loss: 0.0016743207233957946 | new best model!\n",
            "epoch 196 | validation loss: 0.0017336579039692879\n",
            "epoch 197 | validation loss: 0.001651888363994658 | new best model!\n",
            "epoch 198 | validation loss: 0.0016705209272913635\n",
            "epoch 199 | validation loss: 0.0016366029740311205 | new best model!\n",
            "epoch 200 | validation loss: 0.0016665833536535501\n",
            "epoch 201 | validation loss: 0.001623653864953667 | new best model!\n",
            "epoch 202 | validation loss: 0.0015796557418070734 | new best model!\n",
            "epoch 203 | validation loss: 0.00160975253675133\n",
            "epoch 204 | validation loss: 0.001589589868672192\n",
            "epoch 205 | validation loss: 0.0015700685908086598 | new best model!\n",
            "epoch 206 | validation loss: 0.0015040075522847474 | new best model!\n",
            "epoch 207 | validation loss: 0.0015576425939798355\n",
            "epoch 208 | validation loss: 0.0015838327235542238\n",
            "epoch 209 | validation loss: 0.0014550760388374329 | new best model!\n",
            "epoch 210 | validation loss: 0.0015323329134844244\n",
            "epoch 211 | validation loss: 0.0014619482681155205\n",
            "epoch 212 | validation loss: 0.001440008811186999 | new best model!\n",
            "epoch 213 | validation loss: 0.0014404255198314786\n",
            "epoch 214 | validation loss: 0.0014432210009545088\n",
            "epoch 215 | validation loss: 0.0014157116529531777 | new best model!\n",
            "epoch 216 | validation loss: 0.0014341886271722615\n",
            "epoch 217 | validation loss: 0.0014173105591908097\n",
            "epoch 218 | validation loss: 0.0013528745621442795 | new best model!\n",
            "epoch 219 | validation loss: 0.0014771429123356938\n",
            "epoch 220 | validation loss: 0.0013196781510487199 | new best model!\n",
            "epoch 221 | validation loss: 0.0014012848259881139\n",
            "epoch 222 | validation loss: 0.001300441799685359 | new best model!\n",
            "epoch 223 | validation loss: 0.0013806007336825132\n",
            "epoch 224 | validation loss: 0.0012979552848264575 | new best model!\n",
            "epoch 225 | validation loss: 0.0012813807115890086 | new best model!\n",
            "epoch 226 | validation loss: 0.0013061219360679388\n",
            "epoch 227 | validation loss: 0.0012683712993748486 | new best model!\n",
            "epoch 228 | validation loss: 0.0012928031501360238\n",
            "epoch 229 | validation loss: 0.0012453474919311702 | new best model!\n",
            "epoch 230 | validation loss: 0.001230882538948208 | new best model!\n",
            "epoch 231 | validation loss: 0.0013054496957920492\n",
            "epoch 232 | validation loss: 0.00120364292524755 | new best model!\n",
            "epoch 233 | validation loss: 0.001238756231032312\n",
            "epoch 234 | validation loss: 0.0012098631705157459\n",
            "epoch 235 | validation loss: 0.0012080366723239422\n",
            "epoch 236 | validation loss: 0.0011659772135317326 | new best model!\n",
            "epoch 237 | validation loss: 0.001224067120347172\n",
            "epoch 238 | validation loss: 0.0011829923023469746\n",
            "epoch 239 | validation loss: 0.0011662120814435184\n",
            "epoch 240 | validation loss: 0.0011553558288142085 | new best model!\n",
            "epoch 241 | validation loss: 0.0012000667047686875\n",
            "epoch 242 | validation loss: 0.0011343458318151534 | new best model!\n",
            "epoch 243 | validation loss: 0.0011394183966331184\n",
            "epoch 244 | validation loss: 0.0011733871069736779\n",
            "epoch 245 | validation loss: 0.0011119539849460125 | new best model!\n",
            "epoch 246 | validation loss: 0.001151718315668404\n",
            "epoch 247 | validation loss: 0.001115688297431916\n",
            "epoch 248 | validation loss: 0.001092807826353237 | new best model!\n",
            "epoch 249 | validation loss: 0.001111595833208412\n",
            "epoch 250 | validation loss: 0.001132212986703962\n",
            "epoch 251 | validation loss: 0.0010773983085528016 | new best model!\n",
            "epoch 252 | validation loss: 0.0010924666130449623\n",
            "epoch 253 | validation loss: 0.0011430724989622831\n",
            "epoch 254 | validation loss: 0.00105629168683663 | new best model!\n",
            "epoch 255 | validation loss: 0.0010969287541229278\n",
            "epoch 256 | validation loss: 0.0011281309416517615\n",
            "epoch 257 | validation loss: 0.0010511197906453162 | new best model!\n",
            "epoch 258 | validation loss: 0.0012806312297470868\n",
            "epoch 259 | validation loss: 0.0010548723803367466\n",
            "epoch 260 | validation loss: 0.0010453748982399702 | new best model!\n",
            "epoch 261 | validation loss: 0.0011586860055103898\n",
            "epoch 262 | validation loss: 0.0010201196710113436 | new best model!\n",
            "epoch 263 | validation loss: 0.001090738456696272\n",
            "epoch 264 | validation loss: 0.0010320302681066096\n",
            "epoch 265 | validation loss: 0.001020977448206395\n",
            "epoch 266 | validation loss: 0.0010662947897799313\n",
            "epoch 267 | validation loss: 0.0010086228721775115 | new best model!\n",
            "epoch 268 | validation loss: 0.0010271046194247901\n",
            "epoch 269 | validation loss: 0.001014970854157582\n",
            "epoch 270 | validation loss: 0.0010643757705111057\n",
            "epoch 271 | validation loss: 0.0009930907108355314 | new best model!\n",
            "epoch 272 | validation loss: 0.0010402502084616572\n",
            "epoch 273 | validation loss: 0.001011108630336821\n",
            "epoch 274 | validation loss: 0.0009968104714062065\n",
            "epoch 275 | validation loss: 0.001004204124910757\n",
            "epoch 276 | validation loss: 0.0009812891948968172 | new best model!\n",
            "epoch 277 | validation loss: 0.001037487731082365\n",
            "epoch 278 | validation loss: 0.0009665718825999647 | new best model!\n",
            "epoch 279 | validation loss: 0.0009851701615843922\n",
            "epoch 280 | validation loss: 0.0011459995293989778\n",
            "epoch 281 | validation loss: 0.0009775137878023088\n",
            "epoch 282 | validation loss: 0.0010689938790164888\n",
            "epoch 283 | validation loss: 0.0009640221251174808 | new best model!\n",
            "epoch 284 | validation loss: 0.0009555334399919957 | new best model!\n",
            "epoch 285 | validation loss: 0.0010546937410254031\n",
            "epoch 286 | validation loss: 0.0009555368451401591\n",
            "epoch 287 | validation loss: 0.0009988115343730897\n",
            "epoch 288 | validation loss: 0.0009644489036872983\n",
            "epoch 289 | validation loss: 0.000945497362408787 | new best model!\n",
            "epoch 290 | validation loss: 0.0010014058789238334\n",
            "epoch 291 | validation loss: 0.0009436534601263702 | new best model!\n",
            "epoch 292 | validation loss: 0.0009741176618263125\n",
            "epoch 293 | validation loss: 0.0009470906807109714\n",
            "epoch 294 | validation loss: 0.0009324161219410598 | new best model!\n",
            "epoch 295 | validation loss: 0.00095754986978136\n",
            "epoch 296 | validation loss: 0.0009318695520050824 | new best model!\n",
            "epoch 297 | validation loss: 0.0009309386077802628 | new best model!\n",
            "epoch 298 | validation loss: 0.0010094951139762998\n",
            "epoch 299 | validation loss: 0.0009150505065917969 | new best model!\n",
            "epoch 300 | validation loss: 0.0009352262713946402\n",
            "epoch 301 | validation loss: 0.0009401059069205076\n",
            "epoch 302 | validation loss: 0.000911169161554426 | new best model!\n",
            "epoch 303 | validation loss: 0.0009655651520006359\n",
            "epoch 304 | validation loss: 0.0009329888853244483\n",
            "epoch 305 | validation loss: 0.0009021507576107979 | new best model!\n",
            "epoch 306 | validation loss: 0.0009127873345278203\n",
            "epoch 307 | validation loss: 0.0009566380467731506\n",
            "epoch 308 | validation loss: 0.0008982979052234441 | new best model!\n",
            "epoch 309 | validation loss: 0.0009139055327977985\n",
            "epoch 310 | validation loss: 0.0009182202629745007\n",
            "epoch 311 | validation loss: 0.0008960417180787772 | new best model!\n",
            "epoch 312 | validation loss: 0.0009175617888104171\n",
            "epoch 313 | validation loss: 0.0008917439263314009 | new best model!\n",
            "epoch 314 | validation loss: 0.0008872684265952557 | new best model!\n",
            "epoch 315 | validation loss: 0.0009627479303162545\n",
            "epoch 316 | validation loss: 0.0008797984046395868 | new best model!\n",
            "epoch 317 | validation loss: 0.000885127141373232\n",
            "epoch 318 | validation loss: 0.0009586957166902721\n",
            "epoch 319 | validation loss: 0.0008787974365986884 | new best model!\n",
            "epoch 320 | validation loss: 0.000876341771800071 | new best model!\n",
            "epoch 321 | validation loss: 0.0008849896548781544\n",
            "epoch 322 | validation loss: 0.0008960332488641143\n",
            "epoch 323 | validation loss: 0.0008758891781326383 | new best model!\n",
            "epoch 324 | validation loss: 0.0008688250673003495 | new best model!\n",
            "epoch 325 | validation loss: 0.0008912714256439358\n",
            "epoch 326 | validation loss: 0.000893931370228529\n",
            "epoch 327 | validation loss: 0.0008654336561448872 | new best model!\n",
            "epoch 328 | validation loss: 0.000918873178306967\n",
            "epoch 329 | validation loss: 0.0008699377358425409\n",
            "epoch 330 | validation loss: 0.0008679245074745268\n",
            "epoch 331 | validation loss: 0.0009002730948850513\n",
            "epoch 332 | validation loss: 0.0008611136872787029 | new best model!\n",
            "epoch 333 | validation loss: 0.0008795953472144902\n",
            "epoch 334 | validation loss: 0.0008564390300307423 | new best model!\n",
            "epoch 335 | validation loss: 0.0008560435380786657 | new best model!\n",
            "epoch 336 | validation loss: 0.0009023895545396954\n",
            "epoch 337 | validation loss: 0.0008422384271398187 | new best model!\n",
            "epoch 338 | validation loss: 0.0008541792049072683\n",
            "epoch 339 | validation loss: 0.000890315801370889\n",
            "epoch 340 | validation loss: 0.0008354153542313725 | new best model!\n",
            "epoch 341 | validation loss: 0.0008883403788786381\n",
            "epoch 342 | validation loss: 0.0008344960806425661 | new best model!\n",
            "epoch 343 | validation loss: 0.0008518182148691267\n",
            "epoch 344 | validation loss: 0.0008560529095120728\n",
            "epoch 345 | validation loss: 0.000830928998766467 | new best model!\n",
            "epoch 346 | validation loss: 0.0008540606941096485\n",
            "epoch 347 | validation loss: 0.0008330765413120389\n",
            "epoch 348 | validation loss: 0.000824990653200075 | new best model!\n",
            "epoch 349 | validation loss: 0.0008348526025656611\n",
            "epoch 350 | validation loss: 0.0008774199231993407\n",
            "epoch 351 | validation loss: 0.0008220497984439135 | new best model!\n",
            "epoch 352 | validation loss: 0.0008381048392038792\n",
            "epoch 353 | validation loss: 0.0008360521169379354\n",
            "epoch 354 | validation loss: 0.0008228807419072837\n",
            "epoch 355 | validation loss: 0.0008209651277866215 | new best model!\n",
            "epoch 356 | validation loss: 0.0008152817899826914 | new best model!\n",
            "epoch 357 | validation loss: 0.0008306439558509737\n",
            "epoch 358 | validation loss: 0.0008078020473476499 | new best model!\n",
            "epoch 359 | validation loss: 0.000810029567219317\n",
            "epoch 360 | validation loss: 0.0008082606946118176\n",
            "epoch 361 | validation loss: 0.0009080117451958358\n",
            "epoch 362 | validation loss: 0.0007981084345374256 | new best model!\n",
            "epoch 363 | validation loss: 0.0008085909939836711\n",
            "epoch 364 | validation loss: 0.0008213449618779123\n",
            "epoch 365 | validation loss: 0.0008284937939606607\n",
            "epoch 366 | validation loss: 0.0007987338467501104\n",
            "epoch 367 | validation loss: 0.0009088788065128028\n",
            "epoch 368 | validation loss: 0.0007968513236846775 | new best model!\n",
            "epoch 369 | validation loss: 0.0008511387277394533\n",
            "epoch 370 | validation loss: 0.0007896395400166512 | new best model!\n",
            "epoch 371 | validation loss: 0.0007878200558479875 | new best model!\n",
            "epoch 372 | validation loss: 0.0008006432617548853\n",
            "epoch 373 | validation loss: 0.0008024638809729367\n",
            "epoch 374 | validation loss: 0.0007995925843715668\n",
            "epoch 375 | validation loss: 0.0007848669774830341 | new best model!\n",
            "epoch 376 | validation loss: 0.0007859146280679852\n",
            "epoch 377 | validation loss: 0.0008225185738410801\n",
            "epoch 378 | validation loss: 0.0007789023802615702 | new best model!\n",
            "epoch 379 | validation loss: 0.0007917273906059563\n",
            "epoch 380 | validation loss: 0.0007775481208227575 | new best model!\n",
            "epoch 381 | validation loss: 0.0007926145626697689\n",
            "epoch 382 | validation loss: 0.0007795831479597837\n",
            "epoch 383 | validation loss: 0.0007737294363323599 | new best model!\n",
            "epoch 384 | validation loss: 0.0007889130793046206\n",
            "epoch 385 | validation loss: 0.0007966806879267097\n",
            "epoch 386 | validation loss: 0.0007696440443396568 | new best model!\n",
            "epoch 387 | validation loss: 0.0007785242632962763\n",
            "epoch 388 | validation loss: 0.0008002225949894637\n",
            "epoch 389 | validation loss: 0.0007653503271285444 | new best model!\n",
            "epoch 390 | validation loss: 0.0007977284258231521\n",
            "epoch 391 | validation loss: 0.0008043561829254031\n",
            "epoch 392 | validation loss: 0.0008160147117450833\n",
            "epoch 393 | validation loss: 0.0008290236291941255\n",
            "epoch 394 | validation loss: 0.0007941899239085615\n",
            "epoch 395 | validation loss: 0.0007753572717774659\n",
            "epoch 396 | validation loss: 0.0008482765406370163\n",
            "epoch 397 | validation loss: 0.0007656693342141807\n",
            "epoch 398 | validation loss: 0.0007730824872851372\n",
            "epoch 399 | validation loss: 0.0008582386944908649\n",
            "epoch 400 | validation loss: 0.0007532212766818702 | new best model!\n",
            "epoch 401 | validation loss: 0.0007528025016654283 | new best model!\n",
            "epoch 402 | validation loss: 0.00078469721483998\n",
            "epoch 403 | validation loss: 0.0007628458261024207\n",
            "epoch 404 | validation loss: 0.0007990982849150896\n",
            "epoch 405 | validation loss: 0.0007462967769242823 | new best model!\n",
            "epoch 406 | validation loss: 0.0007486090471502393\n",
            "epoch 407 | validation loss: 0.0008151339716278017\n",
            "epoch 408 | validation loss: 0.0007425839721690863 | new best model!\n",
            "epoch 409 | validation loss: 0.0007398718153126538 | new best model!\n",
            "epoch 410 | validation loss: 0.0007689345511607826\n",
            "epoch 411 | validation loss: 0.0007458277104888111\n",
            "epoch 412 | validation loss: 0.0007414013089146465\n",
            "epoch 413 | validation loss: 0.0007627996383234859\n",
            "epoch 414 | validation loss: 0.0007347760838456452 | new best model!\n",
            "epoch 415 | validation loss: 0.0007387590885628015\n",
            "epoch 416 | validation loss: 0.0007469469856005162\n",
            "epoch 417 | validation loss: 0.0007648165919817984\n",
            "epoch 418 | validation loss: 0.0007314977410715073 | new best model!\n",
            "epoch 419 | validation loss: 0.0007382334733847529\n",
            "epoch 420 | validation loss: 0.000735855515813455\n",
            "epoch 421 | validation loss: 0.0007323948375415057\n",
            "epoch 422 | validation loss: 0.000741114403354004\n",
            "epoch 423 | validation loss: 0.0007648478785995394\n",
            "epoch 424 | validation loss: 0.0007243427389767021 | new best model!\n",
            "epoch 425 | validation loss: 0.0007452463905792683\n",
            "epoch 426 | validation loss: 0.0007300593715626746\n",
            "epoch 427 | validation loss: 0.0007334512483794242\n",
            "epoch 428 | validation loss: 0.0007251126517076045\n",
            "epoch 429 | validation loss: 0.0007209021132439375 | new best model!\n",
            "epoch 430 | validation loss: 0.0007261753489729017\n",
            "epoch 431 | validation loss: 0.0007268548069987446\n",
            "epoch 432 | validation loss: 0.0007446915551554412\n",
            "epoch 433 | validation loss: 0.0007183307898230851 | new best model!\n",
            "epoch 434 | validation loss: 0.0007151920290198177 | new best model!\n",
            "epoch 435 | validation loss: 0.0007304798346012831\n",
            "epoch 436 | validation loss: 0.00071533108712174\n",
            "epoch 437 | validation loss: 0.0007139966764952987 | new best model!\n",
            "epoch 438 | validation loss: 0.0007544584223069251\n",
            "epoch 439 | validation loss: 0.0007360696909017861\n",
            "epoch 440 | validation loss: 0.0007248986512422562\n",
            "epoch 441 | validation loss: 0.0007434436702169478\n",
            "epoch 442 | validation loss: 0.0007070177816785872 | new best model!\n",
            "epoch 443 | validation loss: 0.0007179289241321385\n",
            "epoch 444 | validation loss: 0.0008038837113417685\n",
            "epoch 445 | validation loss: 0.0007019663462415338 | new best model!\n",
            "epoch 446 | validation loss: 0.000706969469320029\n",
            "epoch 447 | validation loss: 0.0007858069147914648\n",
            "epoch 448 | validation loss: 0.0007016621530056 | new best model!\n",
            "epoch 449 | validation loss: 0.0007081142684910446\n",
            "epoch 450 | validation loss: 0.0007606370782013983\n",
            "epoch 451 | validation loss: 0.0007153685728553683\n",
            "epoch 452 | validation loss: 0.0007561496167909354\n",
            "epoch 453 | validation loss: 0.0007340639713220298\n",
            "epoch 454 | validation loss: 0.0007012870337348431 | new best model!\n",
            "epoch 455 | validation loss: 0.0007694680243730545\n",
            "epoch 456 | validation loss: 0.0007226044544950128\n",
            "epoch 457 | validation loss: 0.0007410903344862163\n",
            "epoch 458 | validation loss: 0.0008153175294864923\n",
            "epoch 459 | validation loss: 0.000713752320734784\n",
            "epoch 460 | validation loss: 0.0007552832539658993\n",
            "epoch 461 | validation loss: 0.0008045833092182875\n",
            "epoch 462 | validation loss: 0.000703799509210512\n",
            "epoch 463 | validation loss: 0.000694068061420694 | new best model!\n",
            "epoch 464 | validation loss: 0.0007311037043109536\n",
            "epoch 465 | validation loss: 0.0007033172296360135\n",
            "epoch 466 | validation loss: 0.0006938873266335577 | new best model!\n",
            "epoch 467 | validation loss: 0.000688116269884631 | new best model!\n",
            "epoch 468 | validation loss: 0.0007204981811810285\n",
            "epoch 469 | validation loss: 0.0006879523571114987 | new best model!\n",
            "epoch 470 | validation loss: 0.000718103110557422\n",
            "epoch 471 | validation loss: 0.0006953413248993456\n",
            "epoch 472 | validation loss: 0.0006894175603520125\n",
            "epoch 473 | validation loss: 0.0006871825025882572 | new best model!\n",
            "epoch 474 | validation loss: 0.0006966393848415464\n",
            "epoch 475 | validation loss: 0.0006910280208103359\n",
            "epoch 476 | validation loss: 0.0006832851213403046 | new best model!\n",
            "epoch 477 | validation loss: 0.0006987743836361915\n",
            "epoch 478 | validation loss: 0.0006891950033605099\n",
            "epoch 479 | validation loss: 0.0006766082806279883 | new best model!\n",
            "epoch 480 | validation loss: 0.000717729126336053\n",
            "epoch 481 | validation loss: 0.0006802143761888146\n",
            "epoch 482 | validation loss: 0.0006847658951301128\n",
            "epoch 483 | validation loss: 0.0006784200377296656\n",
            "epoch 484 | validation loss: 0.0006919462175574154\n",
            "epoch 485 | validation loss: 0.0006745530408807099 | new best model!\n",
            "epoch 486 | validation loss: 0.0006927165086381137\n",
            "epoch 487 | validation loss: 0.0006906466442160308\n",
            "epoch 488 | validation loss: 0.0006726086721755564 | new best model!\n",
            "epoch 489 | validation loss: 0.0006760972319170833\n",
            "epoch 490 | validation loss: 0.0006805374869145453\n",
            "epoch 491 | validation loss: 0.0006749295280314982\n",
            "epoch 492 | validation loss: 0.0006736590585205704\n",
            "epoch 493 | validation loss: 0.0007056499307509512\n",
            "epoch 494 | validation loss: 0.000700215547112748\n",
            "epoch 495 | validation loss: 0.000681147605064325\n",
            "epoch 496 | validation loss: 0.0007261503196787089\n",
            "epoch 497 | validation loss: 0.0006864420720376074\n",
            "epoch 498 | validation loss: 0.0006924680055817589\n",
            "epoch 499 | validation loss: 0.0006775568763259798\n",
            "epoch 500 | validation loss: 0.0007377361471299082\n",
            "epoch 501 | validation loss: 0.0006718910008203238 | new best model!\n",
            "epoch 502 | validation loss: 0.0007137902721296996\n",
            "epoch 503 | validation loss: 0.0006633042503381148 | new best model!\n",
            "epoch 504 | validation loss: 0.0006668472196906805\n",
            "epoch 505 | validation loss: 0.0006718343356624246\n",
            "epoch 506 | validation loss: 0.000664544029859826\n",
            "epoch 507 | validation loss: 0.0006622779474128038 | new best model!\n",
            "epoch 508 | validation loss: 0.0007252737996168435\n",
            "epoch 509 | validation loss: 0.0006754622154403478\n",
            "epoch 510 | validation loss: 0.0006732161855325103\n",
            "epoch 511 | validation loss: 0.0006898375577293336\n",
            "epoch 512 | validation loss: 0.0006784069701097906\n",
            "epoch 513 | validation loss: 0.0006814394291723147\n",
            "epoch 514 | validation loss: 0.0007314323738683015\n",
            "epoch 515 | validation loss: 0.0006569373072125018 | new best model!\n",
            "epoch 516 | validation loss: 0.0006718715449096635\n",
            "epoch 517 | validation loss: 0.0007413829152937979\n",
            "epoch 518 | validation loss: 0.0006618867628276348\n",
            "epoch 519 | validation loss: 0.0006583998765563592\n",
            "epoch 520 | validation loss: 0.0006680980150122195\n",
            "epoch 521 | validation loss: 0.0006553829734912142 | new best model!\n",
            "epoch 522 | validation loss: 0.0006691254966426641\n",
            "epoch 523 | validation loss: 0.0006535132270073518 | new best model!\n",
            "epoch 524 | validation loss: 0.0006786434096284211\n",
            "epoch 525 | validation loss: 0.0006551524420501664\n",
            "epoch 526 | validation loss: 0.0006527501827804372 | new best model!\n",
            "epoch 527 | validation loss: 0.0006782180571462959\n",
            "epoch 528 | validation loss: 0.0006666048429906368\n",
            "epoch 529 | validation loss: 0.0006527123332489282 | new best model!\n",
            "epoch 530 | validation loss: 0.0006827383767813444\n",
            "epoch 531 | validation loss: 0.0006482795288320631 | new best model!\n",
            "epoch 532 | validation loss: 0.000649516936391592\n",
            "epoch 533 | validation loss: 0.000655079900752753\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Parameter update\u001b[39;00m\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[0;32m~/Documents/Trading_bot/.venv/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Trading_bot/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Trading_bot/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hp_results = [ModelInfo(loss=float(np.inf)) for i in range(len(HP_combinations))]\n",
        "\n",
        "for k, (seq_length, batch_size, lr, num_fc, h_size, num_lstm) in enumerate(HP_combinations):\n",
        "    # Create data processing object\n",
        "    data_process = DataProcessing(seq_length=seq_length, batch_size=batch_size)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader, val_loader, _ = data_process.get_process_data()\n",
        "\n",
        "    # Store current hyper parameter config\n",
        "    hp_results.append(Hyperparams(lr, h_size, num_fc, num_lstm))\n",
        "\n",
        "    # Create LSTM object and move it to the GPU\n",
        "    lstm = LSTM(output_size, input_size, h_size, num_lstm, num_fc, device).to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = torch.optim.Adam(lstm.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    epochs_wo_improvement = 0\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        if epochs_wo_improvement > 50:\n",
        "            print('early stopping!')\n",
        "            break\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, targets = data\n",
        "            targets = targets.reshape(targets.shape[0],1)\n",
        "\n",
        "            inputs  = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = lstm.forward(inputs)\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, targets)\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            # Parameter update\n",
        "            optimizer.step()\n",
        "\n",
        "        val_results         = ModelInfo()\n",
        "        val_results.loss    = 0\n",
        "        val_results.params  = deepcopy(lstm.state_dict())\n",
        "        val_results.model   = deepcopy(lstm)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, val_data in enumerate(val_loader, 0):\n",
        "                val_inputs, val_targets = val_data\n",
        "                val_targets = val_targets.reshape(val_targets.shape[0], 1)\n",
        "\n",
        "                val_inputs  = val_inputs.to(device)\n",
        "                val_targets = val_targets.to(device)\n",
        "\n",
        "                val_outputs = lstm.forward(val_inputs)\n",
        "                val_loss = criterion(val_outputs, val_targets)\n",
        "\n",
        "                for i in range(val_inputs.shape[0]):\n",
        "                    single_input = val_inputs[i].flatten()\n",
        "                    single_label = val_targets[i]\n",
        "                    single_output = val_outputs[i]\n",
        "\n",
        "                    val_results.inputs.append(single_input)\n",
        "                    val_results.labels.append(single_label)\n",
        "                    val_results.outputs.append(single_output)\n",
        "\n",
        "                val_results.loss += float(val_loss.item())\n",
        "        val_results.loss /= len(val_loader)\n",
        "\n",
        "        if hp_results[k].loss > val_results.loss:\n",
        "            val_results.train_loader  = deepcopy(train_loader)\n",
        "            val_results.val_loader    = deepcopy(val_loader)\n",
        "            val_results.input_scaler  = deepcopy(hp_results[k].input_scaler)\n",
        "            val_results.output_scaler = deepcopy(hp_results[k].output_scaler)\n",
        "            hp_results[k]             = deepcopy(val_results)\n",
        "\n",
        "            print(f'epoch {epoch} | validation loss: {val_results.loss} | new best model!')\n",
        "            epochs_wo_improvement = 0\n",
        "        else:\n",
        "            print(f'epoch {epoch} | validation loss: {val_results.loss}')\n",
        "            epochs_wo_improvement += 1\n",
        "\n",
        "    X_test_norm, y_test_norm = data_process.X_test_norm, data_process.y_test_norm \n",
        "\n",
        "    lstm_test = hp_results[k].model\n",
        "\n",
        "    lstm_test.load_state_dict(hp_results[k].params)\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    lstm_test.eval()\n",
        "\n",
        "    X_test_norm = X_test_norm.to(device)\n",
        "    test_output = lstm_test.forward(X_test_norm).to(device)\n",
        "\n",
        "    test_output_np = test_output.cpu().data.numpy()\n",
        "    test_labels_np = y_test_norm.data.numpy()\n",
        "    test_labels_np = test_labels_np.reshape(test_labels_np.shape[0], 1)\n",
        "\n",
        "    X_plot = data_process.in_scaler.inverse_transform(test_output_np)\n",
        "    y_plot = data_process.out_scaler.inverse_transform(test_labels_np)\n",
        "\n",
        "    errors = np.abs(X_plot - y_plot)\n",
        "    avg_error = np.mean(errors)\n",
        "    print(f'Average test error: {avg_error}\\n')\n",
        "\n",
        "    hp_results[-1].avg_val_error\n",
        "\n",
        "best_avg_val_loss = np.inf\n",
        "best_config       = None\n",
        "for hp_result in hp_results:\n",
        "    if hp_result.avg_val_loss < best_avg_val_loss:\n",
        "        best_config = hp_result\n",
        "        best_avg_val_loss = hp_result.avg_val_loss\n",
        "print('----------')\n",
        "print(f'Best config:')\n",
        "print(f'    learning rate       : {hp_result.learning_rate}')\n",
        "print(f'    hidden size         : {hp_result.hidden_size}')\n",
        "print(f'    num of fc features  : {hp_result.hidden_size}')\n",
        "print(f'    num of lstm layers  : {hp_result.hidden_size}')\n",
        "print(f'    AVERAGE VAL ERROR   : {hp_result.avg_val_loss}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
